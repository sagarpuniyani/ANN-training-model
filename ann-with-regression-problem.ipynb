{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-01T17:15:27.152033Z","iopub.execute_input":"2023-07-01T17:15:27.152550Z","iopub.status.idle":"2023-07-01T17:15:27.177196Z","shell.execute_reply.started":"2023-07-01T17:15:27.152515Z","shell.execute_reply":"2023-07-01T17:15:27.176054Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/graduate-admissions/Admission_Predict.csv\n/kaggle/input/graduate-admissions/Admission_Predict_Ver1.1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/graduate-admissions/Admission_Predict_Ver1.1.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:28.407626Z","iopub.execute_input":"2023-07-01T17:15:28.408212Z","iopub.status.idle":"2023-07-01T17:15:28.418393Z","shell.execute_reply.started":"2023-07-01T17:15:28.408183Z","shell.execute_reply":"2023-07-01T17:15:28.417509Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:28.915392Z","iopub.execute_input":"2023-07-01T17:15:28.915781Z","iopub.status.idle":"2023-07-01T17:15:28.937398Z","shell.execute_reply.started":"2023-07-01T17:15:28.915709Z","shell.execute_reply":"2023-07-01T17:15:28.936489Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n0             1        337          118                  4  4.5   4.5  9.65   \n1             2        324          107                  4  4.0   4.5  8.87   \n2             3        316          104                  3  3.0   3.5  8.00   \n3             4        322          110                  3  3.5   2.5  8.67   \n4             5        314          103                  2  2.0   3.0  8.21   \n..          ...        ...          ...                ...  ...   ...   ...   \n495         496        332          108                  5  4.5   4.0  9.02   \n496         497        337          117                  5  5.0   5.0  9.87   \n497         498        330          120                  5  4.5   5.0  9.56   \n498         499        312          103                  4  4.0   5.0  8.43   \n499         500        327          113                  4  4.5   4.5  9.04   \n\n     Research  Chance of Admit   \n0           1              0.92  \n1           1              0.76  \n2           1              0.72  \n3           1              0.80  \n4           0              0.65  \n..        ...               ...  \n495         1              0.87  \n496         1              0.96  \n497         1              0.93  \n498         0              0.73  \n499         0              0.84  \n\n[500 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Serial No.</th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>496</td>\n      <td>332</td>\n      <td>108</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>9.02</td>\n      <td>1</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>497</td>\n      <td>337</td>\n      <td>117</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.87</td>\n      <td>1</td>\n      <td>0.96</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>498</td>\n      <td>330</td>\n      <td>120</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>5.0</td>\n      <td>9.56</td>\n      <td>1</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>499</td>\n      <td>312</td>\n      <td>103</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>8.43</td>\n      <td>0</td>\n      <td>0.73</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>500</td>\n      <td>327</td>\n      <td>113</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.04</td>\n      <td>0</td>\n      <td>0.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:29.368110Z","iopub.execute_input":"2023-07-01T17:15:29.368525Z","iopub.status.idle":"2023-07-01T17:15:29.374886Z","shell.execute_reply.started":"2023-07-01T17:15:29.368494Z","shell.execute_reply":"2023-07-01T17:15:29.373899Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(500, 9)"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:29.735017Z","iopub.execute_input":"2023-07-01T17:15:29.735668Z","iopub.status.idle":"2023-07-01T17:15:29.747823Z","shell.execute_reply.started":"2023-07-01T17:15:29.735634Z","shell.execute_reply":"2023-07-01T17:15:29.747044Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 9 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Serial No.         500 non-null    int64  \n 1   GRE Score          500 non-null    int64  \n 2   TOEFL Score        500 non-null    int64  \n 3   University Rating  500 non-null    int64  \n 4   SOP                500 non-null    float64\n 5   LOR                500 non-null    float64\n 6   CGPA               500 non-null    float64\n 7   Research           500 non-null    int64  \n 8   Chance of Admit    500 non-null    float64\ndtypes: float64(4), int64(5)\nmemory usage: 35.3 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:30.037775Z","iopub.execute_input":"2023-07-01T17:15:30.038153Z","iopub.status.idle":"2023-07-01T17:15:30.046509Z","shell.execute_reply.started":"2023-07-01T17:15:30.038124Z","shell.execute_reply":"2023-07-01T17:15:30.045571Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"#End goal is not making the making as good neural network\ndf.drop(columns=['Serial No.'] , inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:30.841364Z","iopub.execute_input":"2023-07-01T17:15:30.841781Z","iopub.status.idle":"2023-07-01T17:15:30.847038Z","shell.execute_reply.started":"2023-07-01T17:15:30.841722Z","shell.execute_reply":"2023-07-01T17:15:30.846145Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:31.549554Z","iopub.execute_input":"2023-07-01T17:15:31.549948Z","iopub.status.idle":"2023-07-01T17:15:31.568599Z","shell.execute_reply.started":"2023-07-01T17:15:31.549919Z","shell.execute_reply":"2023-07-01T17:15:31.567662Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n0          337          118                  4  4.5   4.5  9.65         1   \n1          324          107                  4  4.0   4.5  8.87         1   \n2          316          104                  3  3.0   3.5  8.00         1   \n3          322          110                  3  3.5   2.5  8.67         1   \n4          314          103                  2  2.0   3.0  8.21         0   \n..         ...          ...                ...  ...   ...   ...       ...   \n495        332          108                  5  4.5   4.0  9.02         1   \n496        337          117                  5  5.0   5.0  9.87         1   \n497        330          120                  5  4.5   5.0  9.56         1   \n498        312          103                  4  4.0   5.0  8.43         0   \n499        327          113                  4  4.5   4.5  9.04         0   \n\n     Chance of Admit   \n0                0.92  \n1                0.76  \n2                0.72  \n3                0.80  \n4                0.65  \n..                ...  \n495              0.87  \n496              0.96  \n497              0.93  \n498              0.73  \n499              0.84  \n\n[500 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>332</td>\n      <td>108</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>9.02</td>\n      <td>1</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>337</td>\n      <td>117</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.87</td>\n      <td>1</td>\n      <td>0.96</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>330</td>\n      <td>120</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>5.0</td>\n      <td>9.56</td>\n      <td>1</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>312</td>\n      <td>103</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>8.43</td>\n      <td>0</td>\n      <td>0.73</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>327</td>\n      <td>113</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.04</td>\n      <td>0</td>\n      <td>0.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows Ã— 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = df.iloc[: , 0:-1]\ny = df.iloc[: , -1]","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:32.198980Z","iopub.execute_input":"2023-07-01T17:15:32.199935Z","iopub.status.idle":"2023-07-01T17:15:32.204255Z","shell.execute_reply.started":"2023-07-01T17:15:32.199899Z","shell.execute_reply":"2023-07-01T17:15:32.203482Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:33.808555Z","iopub.execute_input":"2023-07-01T17:15:33.808916Z","iopub.status.idle":"2023-07-01T17:15:33.825141Z","shell.execute_reply.started":"2023-07-01T17:15:33.808889Z","shell.execute_reply":"2023-07-01T17:15:33.824433Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n0          337          118                  4  4.5   4.5  9.65         1\n1          324          107                  4  4.0   4.5  8.87         1\n2          316          104                  3  3.0   3.5  8.00         1\n3          322          110                  3  3.5   2.5  8.67         1\n4          314          103                  2  2.0   3.0  8.21         0\n..         ...          ...                ...  ...   ...   ...       ...\n495        332          108                  5  4.5   4.0  9.02         1\n496        337          117                  5  5.0   5.0  9.87         1\n497        330          120                  5  4.5   5.0  9.56         1\n498        312          103                  4  4.0   5.0  8.43         0\n499        327          113                  4  4.5   4.5  9.04         0\n\n[500 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>332</td>\n      <td>108</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>9.02</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>337</td>\n      <td>117</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.87</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>330</td>\n      <td>120</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>5.0</td>\n      <td>9.56</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>312</td>\n      <td>103</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>8.43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>327</td>\n      <td>113</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.04</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:34.245785Z","iopub.execute_input":"2023-07-01T17:15:34.246932Z","iopub.status.idle":"2023-07-01T17:15:34.259249Z","shell.execute_reply.started":"2023-07-01T17:15:34.246888Z","shell.execute_reply":"2023-07-01T17:15:34.256015Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0      0.92\n1      0.76\n2      0.72\n3      0.80\n4      0.65\n       ... \n495    0.87\n496    0.96\n497    0.93\n498    0.73\n499    0.84\nName: Chance of Admit , Length: 500, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2 , random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:38.777590Z","iopub.execute_input":"2023-07-01T17:15:38.777965Z","iopub.status.idle":"2023-07-01T17:15:39.337892Z","shell.execute_reply.started":"2023-07-01T17:15:38.777936Z","shell.execute_reply":"2023-07-01T17:15:39.336909Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:40.107068Z","iopub.execute_input":"2023-07-01T17:15:40.107484Z","iopub.status.idle":"2023-07-01T17:15:40.118042Z","shell.execute_reply.started":"2023-07-01T17:15:40.107452Z","shell.execute_reply":"2023-07-01T17:15:40.117142Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_train_scaled","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:41.511370Z","iopub.execute_input":"2023-07-01T17:15:41.511844Z","iopub.status.idle":"2023-07-01T17:15:41.518839Z","shell.execute_reply.started":"2023-07-01T17:15:41.511808Z","shell.execute_reply":"2023-07-01T17:15:41.517806Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n        0.        ],\n       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n        1.        ],\n       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n        0.        ],\n       ...,\n       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n        1.        ],\n       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n        1.        ],\n       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n        0.        ]])"},"metadata":{}}]},{"cell_type":"code","source":"X_test_scaled","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:43.097106Z","iopub.execute_input":"2023-07-01T17:15:43.097479Z","iopub.status.idle":"2023-07-01T17:15:43.110961Z","shell.execute_reply.started":"2023-07-01T17:15:43.097453Z","shell.execute_reply":"2023-07-01T17:15:43.109975Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([[ 0.46      ,  0.5       ,  0.25      ,  0.375     ,  0.14285714,\n         0.5224359 ,  0.        ],\n       [ 0.44      ,  0.53571429,  0.5       ,  0.5       ,  0.42857143,\n         0.53205128,  1.        ],\n       [ 0.98      ,  0.96428571,  1.        ,  0.875     ,  0.71428571,\n         0.92948718,  0.        ],\n       [ 0.52      ,  0.53571429,  0.25      ,  0.625     ,  0.57142857,\n         0.58974359,  1.        ],\n       [ 0.7       ,  0.64285714,  0.75      ,  0.875     ,  0.71428571,\n         0.69230769,  1.        ],\n       [ 0.42      ,  0.32142857,  0.25      ,  0.375     ,  0.57142857,\n         0.49358974,  1.        ],\n       [ 0.6       ,  0.42857143,  0.5       ,  0.5       ,  0.57142857,\n         0.62179487,  1.        ],\n       [ 0.74      ,  0.39285714,  0.5       ,  0.75      ,  0.71428571,\n         0.48076923,  1.        ],\n       [ 0.62      ,  0.67857143,  0.5       ,  0.625     ,  0.71428571,\n         0.65064103,  1.        ],\n       [ 0.56      ,  0.5       ,  0.25      ,  0.75      ,  0.71428571,\n         0.35897436,  1.        ],\n       [ 0.48      ,  0.53571429,  0.25      ,  0.375     ,  0.71428571,\n         0.47115385,  0.        ],\n       [ 0.06      ,  0.17857143,  0.25      ,  0.25      ,  0.71428571,\n         0.32051282,  1.        ],\n       [ 0.74      ,  0.42857143,  1.        ,  0.5       ,  0.57142857,\n         0.65384615,  1.        ],\n       [ 0.74      ,  0.78571429,  0.5       ,  0.5       ,  0.42857143,\n         0.71153846,  0.        ],\n       [ 0.62      ,  0.60714286,  0.5       ,  0.625     ,  0.57142857,\n         0.64102564,  1.        ],\n       [ 0.68      ,  0.71428571,  1.        ,  1.        ,  1.        ,\n         0.73076923,  1.        ],\n       [ 0.32      ,  0.39285714,  0.5       ,  0.625     ,  0.42857143,\n         0.45192308,  0.        ],\n       [ 0.46      ,  0.60714286,  0.5       ,  0.75      ,  0.57142857,\n         0.70512821,  0.        ],\n       [ 0.82      ,  0.82142857,  1.        ,  0.75      ,  0.57142857,\n         0.84615385,  1.        ],\n       [ 0.5       ,  0.46428571,  0.5       ,  0.25      ,  0.28571429,\n         0.53846154,  0.        ],\n       [ 0.44      ,  0.21428571,  0.        ,  0.625     ,  0.42857143,\n         0.44230769,  1.        ],\n       [ 0.42      ,  0.53571429,  0.75      ,  0.875     ,  0.85714286,\n         0.70512821,  1.        ],\n       [ 0.76      ,  0.57142857,  0.75      ,  0.875     ,  0.71428571,\n         0.76282051,  1.        ],\n       [ 0.16      ,  0.32142857,  0.75      ,  0.375     ,  0.85714286,\n         0.28525641,  1.        ],\n       [ 0.7       ,  0.71428571,  0.75      ,  0.625     ,  0.57142857,\n         0.67948718,  0.        ],\n       [ 0.5       ,  0.46428571,  0.25      ,  0.25      ,  0.28571429,\n         0.2724359 ,  0.        ],\n       [ 0.82      ,  0.71428571,  1.        ,  0.75      ,  1.        ,\n         0.96153846,  1.        ],\n       [ 0.36      ,  0.5       ,  0.5       ,  0.5       ,  0.42857143,\n         0.46153846,  0.        ],\n       [ 0.66      ,  0.75      ,  0.75      ,  0.75      ,  0.85714286,\n         0.77884615,  1.        ],\n       [ 0.5       ,  0.64285714,  0.25      ,  0.625     ,  0.42857143,\n         0.53205128,  1.        ],\n       [ 0.34      ,  0.35714286,  0.5       ,  0.5       ,  0.42857143,\n         0.47115385,  0.        ],\n       [ 0.66      ,  0.64285714,  0.5       ,  0.75      ,  0.57142857,\n         0.73717949,  1.        ],\n       [ 0.28      ,  0.28571429,  0.25      ,  0.375     ,  0.57142857,\n         0.40705128,  0.        ],\n       [ 0.82      ,  0.85714286,  0.75      ,  0.875     ,  0.85714286,\n         0.84615385,  1.        ],\n       [ 0.52      ,  0.21428571,  0.        ,  0.125     ,  0.14285714,\n         0.20192308,  0.        ],\n       [ 0.72      ,  0.71428571,  0.5       ,  0.625     ,  0.42857143,\n         0.73717949,  1.        ],\n       [ 0.6       ,  0.32142857,  0.25      ,  0.375     ,  0.42857143,\n         0.58333333,  0.        ],\n       [ 0.48      ,  0.39285714,  0.25      ,  0.25      ,  0.42857143,\n         0.45192308,  0.        ],\n       [ 0.5       ,  0.46428571,  0.25      ,  0.5       ,  0.42857143,\n         0.49358974,  0.        ],\n       [ 0.88      ,  0.85714286,  0.75      ,  0.75      ,  0.57142857,\n         0.87820513,  1.        ],\n       [ 0.18      ,  0.28571429,  0.5       ,  0.25      ,  0.14285714,\n         0.39102564,  0.        ],\n       [ 0.42      ,  0.42857143,  0.5       ,  0.75      ,  0.57142857,\n         0.42628205,  1.        ],\n       [ 0.56      ,  0.32142857,  1.        ,  0.625     ,  1.        ,\n         0.63461538,  1.        ],\n       [ 0.86      ,  0.96428571,  1.        ,  1.        ,  0.85714286,\n         0.95512821,  1.        ],\n       [ 0.74      ,  0.75      ,  0.5       ,  0.625     ,  0.42857143,\n         0.59615385,  1.        ],\n       [ 0.14      ,  0.14285714,  0.25      ,  0.375     ,  0.        ,\n         0.34935897,  0.        ],\n       [ 0.54      ,  0.28571429,  0.25      ,  0.5       ,  0.28571429,\n         0.56730769,  0.        ],\n       [ 0.5       ,  0.42857143,  0.5       ,  0.75      ,  0.28571429,\n         0.41666667,  0.        ],\n       [ 0.64      ,  0.39285714,  0.75      ,  0.5       ,  0.28571429,\n         0.39102564,  1.        ],\n       [ 0.48      ,  0.5       ,  0.25      ,  0.75      ,  0.57142857,\n         0.46474359,  0.        ],\n       [ 0.78      ,  0.67857143,  0.75      ,  0.875     ,  0.71428571,\n         0.70833333,  1.        ],\n       [ 0.82      ,  0.89285714,  0.75      ,  0.875     ,  1.        ,\n         0.83974359,  1.        ],\n       [ 0.8       ,  0.82142857,  1.        ,  0.875     ,  0.42857143,\n         0.81410256,  1.        ],\n       [ 0.36      ,  0.35714286,  0.25      ,  0.25      ,  0.57142857,\n         0.37820513,  1.        ],\n       [ 0.5       ,  0.32142857,  0.5       ,  0.625     ,  0.85714286,\n         0.74679487,  0.        ],\n       [ 0.28      ,  0.46428571,  0.25      ,  0.5       ,  0.42857143,\n         0.44871795,  1.        ],\n       [ 0.44      ,  0.53571429,  0.75      ,  0.875     ,  0.71428571,\n         0.59294872,  1.        ],\n       [ 0.38      ,  0.5       ,  0.25      ,  0.375     ,  0.28571429,\n         0.38461538,  0.        ],\n       [ 0.58      ,  0.5       ,  0.5       ,  0.75      ,  0.42857143,\n         0.38461538,  1.        ],\n       [ 0.56      ,  0.53571429,  0.5       ,  0.5       ,  0.57142857,\n         0.47115385,  1.        ],\n       [ 0.18      ,  0.07142857,  0.        ,  0.        , -0.14285714,\n         0.17307692,  0.        ],\n       [ 0.58      ,  0.39285714,  0.75      ,  0.875     ,  0.57142857,\n         0.59615385,  0.        ],\n       [ 0.68      ,  0.28571429,  0.5       ,  0.75      ,  1.        ,\n         0.58974359,  1.        ],\n       [ 0.8       ,  0.78571429,  0.75      ,  0.875     ,  0.42857143,\n         0.75961538,  1.        ],\n       [ 0.9       ,  0.89285714,  1.        ,  1.        ,  1.        ,\n         0.96794872,  1.        ],\n       [ 0.36      ,  0.42857143,  0.25      ,  0.375     ,  0.42857143,\n         0.40705128,  0.        ],\n       [ 0.6       ,  0.57142857,  0.5       ,  0.625     ,  0.71428571,\n         0.52564103,  1.        ],\n       [ 0.68      ,  0.53571429,  1.        ,  0.625     ,  0.71428571,\n         0.59615385,  1.        ],\n       [ 1.        ,  0.71428571,  0.75      ,  1.        ,  0.85714286,\n         0.91666667,  1.        ],\n       [ 0.56      ,  0.60714286,  0.5       ,  0.5       ,  0.42857143,\n         0.54487179,  0.        ],\n       [ 0.3       ,  0.35714286,  0.25      ,  0.25      ,  0.28571429,\n         0.44230769,  0.        ],\n       [ 0.5       ,  0.42857143,  0.5       ,  0.5       ,  0.28571429,\n         0.49038462,  0.        ],\n       [ 0.72      ,  0.78571429,  0.5       ,  0.5       ,  0.42857143,\n         0.74038462,  1.        ],\n       [ 0.4       ,  0.25      ,  0.25      ,  0.125     ,  0.14285714,\n         0.16025641,  0.        ],\n       [ 0.96      ,  0.89285714,  0.75      ,  0.625     ,  0.85714286,\n         0.8525641 ,  1.        ],\n       [ 0.28      ,  0.53571429,  0.5       ,  0.625     ,  0.42857143,\n         0.33974359,  0.        ],\n       [ 0.84      ,  0.57142857,  1.        ,  0.875     ,  0.71428571,\n         0.71153846,  1.        ],\n       [ 0.66      ,  0.67857143,  1.        ,  0.75      ,  1.        ,\n         0.98076923,  1.        ],\n       [ 0.6       ,  0.42857143,  0.5       ,  0.5       ,  0.28571429,\n         0.56730769,  1.        ],\n       [ 0.48      ,  0.60714286,  0.75      ,  0.625     ,  0.71428571,\n         0.63141026,  1.        ],\n       [ 0.74      ,  0.57142857,  1.        ,  1.        ,  0.57142857,\n         0.74679487,  1.        ],\n       [ 0.        ,  0.42857143,  0.75      ,  0.25      ,  0.28571429,\n         0.21153846,  0.        ],\n       [ 0.9       ,  0.92857143,  1.        ,  0.875     ,  0.57142857,\n         0.84615385,  1.        ],\n       [ 0.74      ,  0.5       ,  0.75      ,  0.75      ,  0.85714286,\n         0.625     ,  1.        ],\n       [ 0.64      ,  0.64285714,  1.        ,  0.875     ,  0.71428571,\n         0.69551282,  0.        ],\n       [ 0.36      ,  0.60714286,  0.25      ,  0.5       ,  0.71428571,\n         0.52884615,  0.        ],\n       [ 0.68      ,  0.75      ,  1.        ,  0.75      ,  1.        ,\n         0.78525641,  1.        ],\n       [ 0.82      ,  0.85714286,  1.        ,  0.75      ,  0.71428571,\n         0.78846154,  1.        ],\n       [ 0.14      ,  0.25      ,  0.75      ,  0.5       ,  0.57142857,\n         0.32371795,  0.        ],\n       [ 0.28      ,  0.42857143,  0.5       ,  0.375     ,  0.14285714,\n         0.42307692,  0.        ],\n       [ 0.38      ,  0.46428571,  0.75      ,  0.625     ,  0.14285714,\n         0.44230769,  0.        ],\n       [ 0.62      ,  0.35714286,  0.5       ,  0.625     ,  0.71428571,\n         0.70833333,  1.        ],\n       [ 0.52      ,  0.39285714,  0.5       ,  0.625     ,  0.14285714,\n         0.28205128,  0.        ],\n       [ 0.62      ,  0.60714286,  0.5       ,  0.5       ,  0.71428571,\n         0.44871795,  1.        ],\n       [ 0.64      ,  0.71428571,  0.75      ,  0.625     ,  0.28571429,\n         0.71153846,  1.        ],\n       [ 0.74      ,  0.67857143,  0.75      ,  0.75      ,  0.85714286,\n         0.70512821,  1.        ],\n       [ 0.64      ,  0.78571429,  1.        ,  0.875     ,  0.71428571,\n         0.68589744,  1.        ],\n       [ 0.16      ,  0.21428571,  0.25      ,  0.75      ,  0.42857143,\n         0.39423077,  0.        ],\n       [ 0.52      ,  0.64285714,  0.5       ,  0.625     ,  0.71428571,\n         0.56410256,  0.        ],\n       [ 0.3       ,  0.57142857,  1.        ,  0.5       ,  0.42857143,\n         0.53846154,  0.        ]])"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:44.221275Z","iopub.execute_input":"2023-07-01T17:15:44.222050Z","iopub.status.idle":"2023-07-01T17:15:47.065847Z","shell.execute_reply.started":"2023-07-01T17:15:44.222002Z","shell.execute_reply":"2023-07-01T17:15:47.064972Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:15:47.067334Z","iopub.execute_input":"2023-07-01T17:15:47.068047Z","iopub.status.idle":"2023-07-01T17:15:47.103176Z","shell.execute_reply.started":"2023-07-01T17:15:47.068018Z","shell.execute_reply":"2023-07-01T17:15:47.102407Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.add(Dense(7, activation='relu', input_dim=7))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dense(1, activation='linear'))","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:16:00.263798Z","iopub.execute_input":"2023-07-01T17:16:00.264222Z","iopub.status.idle":"2023-07-01T17:16:00.324574Z","shell.execute_reply.started":"2023-07-01T17:16:00.264188Z","shell.execute_reply":"2023-07-01T17:16:00.323495Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.summary","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:16:02.126346Z","iopub.execute_input":"2023-07-01T17:16:02.126991Z","iopub.status.idle":"2023-07-01T17:16:02.133328Z","shell.execute_reply.started":"2023-07-01T17:16:02.126955Z","shell.execute_reply":"2023-07-01T17:16:02.132382Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x79f82394fa30>>"},"metadata":{}}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:16:04.155640Z","iopub.execute_input":"2023-07-01T17:16:04.156005Z","iopub.status.idle":"2023-07-01T17:16:04.176067Z","shell.execute_reply.started":"2023-07-01T17:16:04.155980Z","shell.execute_reply":"2023-07-01T17:16:04.175058Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 7)                 56        \n                                                                 \n dense_1 (Dense)             (None, 7)                 56        \n                                                                 \n dense_2 (Dense)             (None, 1)                 8         \n                                                                 \n=================================================================\nTotal params: 120\nTrainable params: 120\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(loss='mean_squared_error' , optimizer='Adam' , metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:16:19.484692Z","iopub.execute_input":"2023-07-01T17:16:19.485661Z","iopub.status.idle":"2023-07-01T17:16:19.504643Z","shell.execute_reply.started":"2023-07-01T17:16:19.485606Z","shell.execute_reply":"2023-07-01T17:16:19.503778Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train_scaled , y_train , epochs=500 , validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:16:21.842916Z","iopub.execute_input":"2023-07-01T17:16:21.843280Z","iopub.status.idle":"2023-07-01T17:16:44.277418Z","shell.execute_reply.started":"2023-07-01T17:16:21.843254Z","shell.execute_reply":"2023-07-01T17:16:44.276487Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/500\n10/10 [==============================] - 1s 23ms/step - loss: 0.5225 - accuracy: 0.0000e+00 - val_loss: 0.3766 - val_accuracy: 0.0000e+00\nEpoch 2/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.0000e+00 - val_loss: 0.1556 - val_accuracy: 0.0000e+00\nEpoch 3/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.0000e+00 - val_loss: 0.0476 - val_accuracy: 0.0000e+00\nEpoch 4/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.0000e+00 - val_loss: 0.0200 - val_accuracy: 0.0000e+00\nEpoch 5/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.0000e+00 - val_loss: 0.0214 - val_accuracy: 0.0000e+00\nEpoch 6/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0000e+00\nEpoch 7/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.0190 - val_accuracy: 0.0000e+00\nEpoch 8/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\nEpoch 9/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0162 - val_accuracy: 0.0000e+00\nEpoch 10/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.0000e+00 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\nEpoch 11/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.0000e+00 - val_loss: 0.0153 - val_accuracy: 0.0000e+00\nEpoch 12/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_accuracy: 0.0000e+00\nEpoch 13/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\nEpoch 14/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.0000e+00 - val_loss: 0.0142 - val_accuracy: 0.0000e+00\nEpoch 15/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_accuracy: 0.0000e+00\nEpoch 16/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\nEpoch 17/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\nEpoch 18/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\nEpoch 19/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\nEpoch 20/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\nEpoch 21/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\nEpoch 22/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\nEpoch 23/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\nEpoch 24/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\nEpoch 25/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\nEpoch 26/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\nEpoch 27/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\nEpoch 28/500\n10/10 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\nEpoch 29/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\nEpoch 30/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\nEpoch 31/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 32/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\nEpoch 33/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\nEpoch 34/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\nEpoch 35/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\nEpoch 36/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\nEpoch 37/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\nEpoch 38/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 39/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\nEpoch 40/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\nEpoch 41/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\nEpoch 42/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\nEpoch 43/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 44/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 45/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\nEpoch 46/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 47/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\nEpoch 48/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\nEpoch 49/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\nEpoch 50/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\nEpoch 51/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\nEpoch 52/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\nEpoch 53/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\nEpoch 54/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\nEpoch 55/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\nEpoch 56/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\nEpoch 57/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\nEpoch 58/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\nEpoch 59/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\nEpoch 60/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\nEpoch 61/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\nEpoch 62/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 63/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\nEpoch 64/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\nEpoch 65/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\nEpoch 66/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\nEpoch 67/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\nEpoch 68/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 69/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 70/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\nEpoch 71/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\nEpoch 72/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 73/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 74/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 75/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 76/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 77/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 78/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 79/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\nEpoch 80/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 81/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 82/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 83/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 84/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 85/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 86/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 87/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 88/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 89/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 90/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 91/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 92/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\nEpoch 93/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 94/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 95/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 96/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 97/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 98/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 99/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\nEpoch 100/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\nEpoch 101/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\nEpoch 102/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\nEpoch 103/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\nEpoch 104/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\nEpoch 105/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\nEpoch 106/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\nEpoch 107/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\nEpoch 108/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\nEpoch 109/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\nEpoch 110/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\nEpoch 111/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\nEpoch 112/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\nEpoch 113/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\nEpoch 114/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\nEpoch 115/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\nEpoch 116/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\nEpoch 117/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\nEpoch 118/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 119/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 120/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 121/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 122/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 123/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 124/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 125/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 126/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\nEpoch 127/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\nEpoch 128/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\nEpoch 129/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\nEpoch 130/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\nEpoch 131/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 132/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 133/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 134/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 135/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 136/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 137/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 138/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 139/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\nEpoch 140/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 141/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\nEpoch 142/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 143/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\nEpoch 144/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\nEpoch 145/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\nEpoch 146/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 147/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 148/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 149/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 150/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 151/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 152/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 153/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 154/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 155/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 156/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 157/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 158/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 159/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 160/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 161/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 162/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 163/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 164/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 165/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 166/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 167/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 168/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 169/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 170/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 171/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 172/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 173/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 174/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 175/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 176/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 177/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 178/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 179/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 180/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 181/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 182/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 183/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 184/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 185/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 186/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 187/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 188/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 189/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 190/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 191/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 192/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 193/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 194/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 195/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 196/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 197/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 198/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 199/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 200/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 201/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 202/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 203/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 204/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 205/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 206/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 207/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 208/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 209/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 210/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 211/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 212/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 213/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 214/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 215/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 216/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 217/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 218/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 219/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 220/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 221/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 222/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 223/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 224/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 225/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 226/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 227/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 228/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 229/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 230/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 231/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 232/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 233/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 234/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 235/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 236/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 237/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 238/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 239/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 240/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 241/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 242/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 243/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 244/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 245/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 246/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 247/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 248/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 249/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 250/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 251/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 252/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 253/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 254/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 255/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 256/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 257/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 258/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 259/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 260/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 261/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 262/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 263/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 264/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 265/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 266/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 267/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 268/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 269/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 270/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 271/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 272/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 273/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 274/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 275/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 276/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 277/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 278/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 279/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 280/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 281/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 282/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 283/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 284/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 285/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 286/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 287/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 288/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 289/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 290/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 291/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 292/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 293/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 294/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 295/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 296/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 297/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 298/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 299/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 300/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 301/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 302/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 303/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 304/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 305/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 306/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 307/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 308/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 309/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 310/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 311/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 312/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 313/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 314/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 315/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 316/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 317/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 318/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 319/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 320/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 321/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 322/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 323/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 324/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 325/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 326/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 327/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 328/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 329/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 330/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 331/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 332/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 333/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 334/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 335/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 336/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 337/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 338/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 339/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 340/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 341/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 342/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 343/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 344/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 345/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 346/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 347/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 348/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 349/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 350/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 351/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 352/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 353/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 354/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 355/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 356/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 357/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 358/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 359/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 360/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 361/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 362/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 363/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 364/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 365/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 366/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 367/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 368/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 369/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 370/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 371/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 372/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 373/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 374/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 375/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 376/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 377/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 378/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 379/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 380/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 381/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 382/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 383/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 384/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 385/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 386/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 387/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 388/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 389/500\n10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 390/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 391/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 392/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 393/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 394/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 395/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 396/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 397/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 398/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 399/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 400/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 401/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 402/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 403/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 404/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 405/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 406/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 407/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 408/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 409/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 410/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 411/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 412/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 413/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 414/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 415/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 416/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 417/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 418/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 419/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 420/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 421/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 422/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 423/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 424/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 425/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 426/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 427/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 428/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 429/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 430/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 431/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 432/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 433/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 434/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 435/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 436/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 437/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 438/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 439/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 440/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 441/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 442/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 443/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 444/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 445/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 446/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 447/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 448/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 449/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 450/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 451/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 452/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 453/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 454/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 455/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 456/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 457/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 458/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 459/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 460/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 461/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 462/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 463/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 464/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 465/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 466/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 467/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 468/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 469/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 470/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 471/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 472/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 473/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 474/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 475/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 476/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 477/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 478/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 479/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 480/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 481/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 482/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 483/500\n10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 484/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 485/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 486/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 487/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 488/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 489/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 490/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 491/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 492/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 493/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 494/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 495/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 496/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 497/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 498/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 499/500\n10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\nEpoch 500/500\n10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"ee.ww\")","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:16:50.750991Z","iopub.execute_input":"2023-07-01T17:16:50.751410Z","iopub.status.idle":"2023-07-01T17:16:51.545524Z","shell.execute_reply.started":"2023-07-01T17:16:50.751363Z","shell.execute_reply":"2023-07-01T17:16:51.544797Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.layers[0].get_weights()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:16:54.026205Z","iopub.execute_input":"2023-07-01T17:16:54.026588Z","iopub.status.idle":"2023-07-01T17:16:54.035652Z","shell.execute_reply.started":"2023-07-01T17:16:54.026556Z","shell.execute_reply":"2023-07-01T17:16:54.034695Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[array([[-0.57578427,  0.5128722 , -0.14503594,  0.06421399, -0.36275142,\n          0.47812358, -0.21953768],\n        [-0.0285677 ,  0.07580616,  0.619949  , -0.42758334,  0.63729507,\n          0.04965395, -0.19366246],\n        [ 0.2856844 ,  0.20551647, -0.61454564, -0.23939359, -0.6351895 ,\n          0.5534311 , -0.58723044],\n        [ 0.23443112,  0.8187611 ,  0.50530344, -0.14123744, -0.3497958 ,\n         -0.3820988 , -0.2309658 ],\n        [-0.56178695,  0.24792759,  0.6567398 , -0.5864807 ,  0.4513809 ,\n         -0.5174829 , -0.2961845 ],\n        [-0.6694041 ,  0.06597929,  0.0465251 , -0.51419175,  0.77241516,\n         -0.05803241, -0.37705645],\n        [ 0.37139633, -0.00086401,  0.45132956, -0.0305984 ,  0.4211504 ,\n          0.01875578, -0.04884058]], dtype=float32),\n array([-0.13719942,  0.06661469, -0.08772383,  0.        ,  0.13074581,\n        -0.04396242,  0.        ], dtype=float32)]"},"metadata":{}}]},{"cell_type":"code","source":"model.layers[1].get_weights()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:16:58.338923Z","iopub.execute_input":"2023-07-01T17:16:58.339298Z","iopub.status.idle":"2023-07-01T17:16:58.348721Z","shell.execute_reply.started":"2023-07-01T17:16:58.339267Z","shell.execute_reply":"2023-07-01T17:16:58.347771Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[array([[-0.30861157, -0.56771874,  0.2681866 , -0.46756572,  0.18613395,\n         -0.38561708,  0.30834836],\n        [-0.17894632,  0.2550179 ,  0.01451774,  0.24173796, -0.02706344,\n          0.23567688,  0.43318638],\n        [-0.16050088,  0.02969037,  0.43402448, -0.3285833 ,  0.36564732,\n          0.07678304,  0.19469456],\n        [-0.6544531 , -0.094607  , -0.34634882,  0.5984819 ,  0.5469066 ,\n         -0.11874253,  0.29846722],\n        [-0.44727695,  0.55749214,  0.44962716,  0.37567082, -0.7476239 ,\n         -0.16425535,  0.29112315],\n        [-0.4457703 , -0.44872698, -0.30335113,  0.4157374 , -0.44591323,\n          0.00551841, -0.35470244],\n        [-0.19430286, -0.6116343 , -0.28508273, -0.06978363, -0.35881692,\n         -0.16778958,  0.48578238]], dtype=float32),\n array([ 0.        ,  0.06200932, -0.14147381,  0.07012583,  0.02667999,\n        -0.04595624,  0.06132496], dtype=float32)]"},"metadata":{}}]},{"cell_type":"code","source":"model.layers[2].get_weights()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:17:08.536587Z","iopub.execute_input":"2023-07-01T17:17:08.537531Z","iopub.status.idle":"2023-07-01T17:17:08.544634Z","shell.execute_reply.started":"2023-07-01T17:17:08.537484Z","shell.execute_reply":"2023-07-01T17:17:08.543784Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[array([[ 0.25032097],\n        [ 0.46839318],\n        [-0.5594462 ],\n        [ 0.623742  ],\n        [-0.25740802],\n        [-0.23683506],\n        [ 0.47475183]], dtype=float32),\n array([0.06029015], dtype=float32)]"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = model.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:17:37.251638Z","iopub.execute_input":"2023-07-01T17:17:37.252481Z","iopub.status.idle":"2023-07-01T17:17:37.399390Z","shell.execute_reply.started":"2023-07-01T17:17:37.252442Z","shell.execute_reply":"2023-07-01T17:17:37.398575Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"4/4 [==============================] - 0s 2ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(y_test , y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:17:42.846283Z","iopub.execute_input":"2023-07-01T17:17:42.846658Z","iopub.status.idle":"2023-07-01T17:17:42.854903Z","shell.execute_reply.started":"2023-07-01T17:17:42.846628Z","shell.execute_reply":"2023-07-01T17:17:42.854087Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0.8030285728776805"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:18:51.858441Z","iopub.execute_input":"2023-07-01T17:18:51.859438Z","iopub.status.idle":"2023-07-01T17:18:51.862762Z","shell.execute_reply.started":"2023-07-01T17:18:51.859403Z","shell.execute_reply":"2023-07-01T17:18:51.862115Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"history.history","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:19:04.065244Z","iopub.execute_input":"2023-07-01T17:19:04.065617Z","iopub.status.idle":"2023-07-01T17:19:04.096337Z","shell.execute_reply.started":"2023-07-01T17:19:04.065587Z","shell.execute_reply":"2023-07-01T17:19:04.095427Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'loss': [0.5225011110305786,\n  0.2739255726337433,\n  0.10678627341985703,\n  0.03700912371277809,\n  0.024217823520302773,\n  0.02437654696404934,\n  0.023099100217223167,\n  0.021208036690950394,\n  0.020155755802989006,\n  0.019456950947642326,\n  0.01886247843503952,\n  0.018273992463946342,\n  0.01776442490518093,\n  0.01718730852007866,\n  0.016665931791067123,\n  0.01616320013999939,\n  0.015698349103331566,\n  0.015279772691428661,\n  0.014851780608296394,\n  0.014428381808102131,\n  0.014053121209144592,\n  0.013684655539691448,\n  0.013301162049174309,\n  0.012961676344275475,\n  0.012658627703785896,\n  0.012332846410572529,\n  0.01203786488622427,\n  0.011760339140892029,\n  0.01151022408157587,\n  0.01125954370945692,\n  0.011016195639967918,\n  0.01082603819668293,\n  0.01057626586407423,\n  0.010407140478491783,\n  0.010211942717432976,\n  0.009988092817366123,\n  0.009791126474738121,\n  0.009631754830479622,\n  0.00946885161101818,\n  0.009292199276387691,\n  0.009143475443124771,\n  0.008975919336080551,\n  0.008842582814395428,\n  0.008736513555049896,\n  0.008567165583372116,\n  0.008450725115835667,\n  0.008315609768033028,\n  0.00819392129778862,\n  0.008078348822891712,\n  0.00796927697956562,\n  0.007860103622078896,\n  0.007751964032649994,\n  0.007659517228603363,\n  0.007549081929028034,\n  0.007446258328855038,\n  0.007363814860582352,\n  0.0073321787640452385,\n  0.0071706040762364864,\n  0.0071032410487532616,\n  0.007026078645139933,\n  0.006929333321750164,\n  0.006872144993394613,\n  0.006808754056692123,\n  0.006736918352544308,\n  0.006654050201177597,\n  0.006604073103517294,\n  0.006531680468469858,\n  0.006465023849159479,\n  0.0064136795699596405,\n  0.006348739378154278,\n  0.006301444955170155,\n  0.006247083656489849,\n  0.0061897998675704,\n  0.0061275893822312355,\n  0.006096198223531246,\n  0.006093671545386314,\n  0.005977966822683811,\n  0.005954804830253124,\n  0.005924082361161709,\n  0.005852094851434231,\n  0.005817047320306301,\n  0.005775630008429289,\n  0.005725698079913855,\n  0.005691465921700001,\n  0.005658301990479231,\n  0.0056120166555047035,\n  0.005579293705523014,\n  0.00555448466911912,\n  0.005548309069126844,\n  0.005466989241540432,\n  0.005462538450956345,\n  0.005421903450042009,\n  0.005402847193181515,\n  0.005382410250604153,\n  0.00532327126711607,\n  0.005323818419128656,\n  0.005341522861272097,\n  0.0052259815856814384,\n  0.0052205948159098625,\n  0.005195967387408018,\n  0.005173962563276291,\n  0.005138705018907785,\n  0.005123653449118137,\n  0.00510034803301096,\n  0.005066426005214453,\n  0.005066152662038803,\n  0.005037809256464243,\n  0.0050031766295433044,\n  0.004992214031517506,\n  0.004961864557117224,\n  0.004951904062181711,\n  0.004937514662742615,\n  0.00490593770518899,\n  0.004894747398793697,\n  0.004868040326982737,\n  0.004850724712014198,\n  0.004832123406231403,\n  0.004810481332242489,\n  0.004794160835444927,\n  0.004779689479619265,\n  0.004760448820888996,\n  0.004749580752104521,\n  0.004732728935778141,\n  0.004734528250992298,\n  0.004707996733486652,\n  0.004685963504016399,\n  0.004686080850660801,\n  0.004656524863094091,\n  0.004639362450689077,\n  0.004638967104256153,\n  0.004607584793120623,\n  0.0045965006574988365,\n  0.0045830183662474155,\n  0.004563939291983843,\n  0.00457461504265666,\n  0.004533605650067329,\n  0.004546112380921841,\n  0.004512022249400616,\n  0.0045121051371097565,\n  0.004531234502792358,\n  0.004546287469565868,\n  0.004524570424109697,\n  0.004445817321538925,\n  0.0044529070146381855,\n  0.004427652340382338,\n  0.004430311266332865,\n  0.004401116631925106,\n  0.004390062298625708,\n  0.004375894088298082,\n  0.004368345253169537,\n  0.004362248815596104,\n  0.004362814128398895,\n  0.00437256321310997,\n  0.004339328967034817,\n  0.004318882245570421,\n  0.004316375590860844,\n  0.004325625952333212,\n  0.004307713359594345,\n  0.004276610445231199,\n  0.004270919598639011,\n  0.004259057808667421,\n  0.004244864918291569,\n  0.004250612575560808,\n  0.004232920706272125,\n  0.004227709956467152,\n  0.004219382535666227,\n  0.004209333099424839,\n  0.00419379910454154,\n  0.004188963212072849,\n  0.004178218077868223,\n  0.0041714562103152275,\n  0.004175816662609577,\n  0.004169783554971218,\n  0.004161930177360773,\n  0.004137466195970774,\n  0.004159014672040939,\n  0.004146595951169729,\n  0.004119844175875187,\n  0.004122200421988964,\n  0.004106785170733929,\n  0.004096868447959423,\n  0.004086856730282307,\n  0.004079488571733236,\n  0.00407495629042387,\n  0.004075055941939354,\n  0.004065928980708122,\n  0.004058742430061102,\n  0.00406330730766058,\n  0.004039696417748928,\n  0.0040401616133749485,\n  0.004031924065202475,\n  0.004026220180094242,\n  0.00402233749628067,\n  0.004023252986371517,\n  0.004017050378024578,\n  0.004091971088200808,\n  0.004041056148707867,\n  0.003989419899880886,\n  0.004021971486508846,\n  0.003998704720288515,\n  0.003978303633630276,\n  0.003974742256104946,\n  0.0039670346304774284,\n  0.003964414354413748,\n  0.003970129415392876,\n  0.003975869622081518,\n  0.003956986591219902,\n  0.003952546510845423,\n  0.003946081735193729,\n  0.003937327302992344,\n  0.0039328825660049915,\n  0.003928967751562595,\n  0.0039259446784853935,\n  0.003923540469259024,\n  0.0039193639531731606,\n  0.0039120027795434,\n  0.003911964129656553,\n  0.0039079757407307625,\n  0.003914336673915386,\n  0.003924028482288122,\n  0.003907090984284878,\n  0.003898952854797244,\n  0.0038840477354824543,\n  0.0038881483487784863,\n  0.003882475197315216,\n  0.0038734073750674725,\n  0.0038696289993822575,\n  0.0038815580774098635,\n  0.003871586872264743,\n  0.003865763545036316,\n  0.003862921614199877,\n  0.003851998597383499,\n  0.003860715078189969,\n  0.003876717295497656,\n  0.0038311562966555357,\n  0.0038528486620634794,\n  0.003856576280668378,\n  0.0038262158632278442,\n  0.0038617909885942936,\n  0.0039023153949528933,\n  0.003967000637203455,\n  0.0038641844876110554,\n  0.003818965284153819,\n  0.003847698913887143,\n  0.003831634996458888,\n  0.0038685433100908995,\n  0.003814206924289465,\n  0.003818405093625188,\n  0.0038190577179193497,\n  0.003811946138739586,\n  0.0037929576355963945,\n  0.0037976428866386414,\n  0.003788819070905447,\n  0.0038332182448357344,\n  0.0037996366154402494,\n  0.003789179725572467,\n  0.0037945848889648914,\n  0.0037786797620356083,\n  0.0037762518040835857,\n  0.0037734531797468662,\n  0.003768718568608165,\n  0.0037761572748422623,\n  0.003775443183258176,\n  0.0037581336218863726,\n  0.0037821095902472734,\n  0.0038037728518247604,\n  0.003789076115936041,\n  0.003803687635809183,\n  0.003761380212381482,\n  0.003752293763682246,\n  0.0037506986409425735,\n  0.0037610833533108234,\n  0.003745385678485036,\n  0.003745945869013667,\n  0.0037497845478355885,\n  0.0037861603777855635,\n  0.0037910197861492634,\n  0.003744834568351507,\n  0.003755953162908554,\n  0.0037319683469831944,\n  0.003730806754902005,\n  0.0037660631351172924,\n  0.0037306309677660465,\n  0.0037295022048056126,\n  0.0037279431708157063,\n  0.0037216399796307087,\n  0.0037043739575892687,\n  0.003728447947651148,\n  0.0037356186658143997,\n  0.003734069410711527,\n  0.0037260963581502438,\n  0.0036962770391255617,\n  0.0037068421952426434,\n  0.0037418403662741184,\n  0.0037162683438509703,\n  0.0037322300486266613,\n  0.0037074133288115263,\n  0.003705753479152918,\n  0.0037112957797944546,\n  0.003705517156049609,\n  0.0036879335530102253,\n  0.0037112620193511248,\n  0.0037096545565873384,\n  0.0037095118314027786,\n  0.0036890539340674877,\n  0.003686492098495364,\n  0.0036770522128790617,\n  0.003696248633787036,\n  0.0036808731965720654,\n  0.003691915888339281,\n  0.0036911561619490385,\n  0.0036668521352112293,\n  0.003684561001136899,\n  0.003691586432978511,\n  0.003656867891550064,\n  0.0037544488441199064,\n  0.003687192453071475,\n  0.0036997683346271515,\n  0.0036430475302040577,\n  0.0036765760742127895,\n  0.0036445234436541796,\n  0.00368637777864933,\n  0.0036456380039453506,\n  0.0036509078927338123,\n  0.0036691799759864807,\n  0.0036450843326747417,\n  0.003638251218944788,\n  0.0036915969103574753,\n  0.0036550145596265793,\n  0.003692682832479477,\n  0.00365510955452919,\n  0.0038037176709622145,\n  0.0037788166664540768,\n  0.00363641744479537,\n  0.0036488049663603306,\n  0.003620688570663333,\n  0.0036056912504136562,\n  0.0036348565481603146,\n  0.0036109653301537037,\n  0.0036169991362839937,\n  0.00361950253136456,\n  0.003613277804106474,\n  0.0036082237493246794,\n  0.003605362493544817,\n  0.0035996045917272568,\n  0.0036145008634775877,\n  0.0036242729984223843,\n  0.0036249742843210697,\n  0.0036587994545698166,\n  0.0036243691574782133,\n  0.0036162403412163258,\n  0.0035892061423510313,\n  0.0035853139124810696,\n  0.0035881013609468937,\n  0.0035889458376914263,\n  0.00360829196870327,\n  0.003592629451304674,\n  0.003587910206988454,\n  0.0035967249423265457,\n  0.0036145609337836504,\n  0.003638995112851262,\n  0.003562629222869873,\n  0.003562789410352707,\n  0.003585210768505931,\n  0.0035663123708218336,\n  0.0035686581395566463,\n  0.0035984881687909365,\n  0.003574537578970194,\n  0.003561763558536768,\n  0.003558430355042219,\n  0.003553468734025955,\n  0.0035889814607799053,\n  0.0035987752489745617,\n  0.003594848560169339,\n  0.0036057536490261555,\n  0.003551993053406477,\n  0.0035873656161129475,\n  0.003555893199518323,\n  0.0035563851706683636,\n  0.003565739141777158,\n  0.003544838400557637,\n  0.003571661189198494,\n  0.0036158603616058826,\n  0.0035629458725452423,\n  0.0036028078757226467,\n  0.0036016851663589478,\n  0.003557927906513214,\n  0.0035683021415024996,\n  0.003553299233317375,\n  0.003539928002282977,\n  0.003554338589310646,\n  0.003549122018739581,\n  0.0035318322479724884,\n  0.0035568017046898603,\n  0.003618859453126788,\n  0.003567555220797658,\n  0.003559804055839777,\n  0.003544831182807684,\n  0.003541977610439062,\n  0.0035386220552027225,\n  0.0035241153091192245,\n  0.0035433280281722546,\n  0.003529967740178108,\n  0.0035147566813975573,\n  0.0035623679868876934,\n  0.003636137116700411,\n  0.0035472544841468334,\n  0.0036144782789051533,\n  0.0035526915453374386,\n  0.0035706558264791965,\n  0.0035374679137021303,\n  0.0035161548294126987,\n  0.0035305358469486237,\n  0.0035483133979141712,\n  0.003530312329530716,\n  0.003494319273158908,\n  0.0035654581151902676,\n  0.003529118839651346,\n  0.003517713863402605,\n  0.0035258226562291384,\n  0.003568558022379875,\n  0.003571417648345232,\n  0.0035004422534257174,\n  0.003494927193969488,\n  0.0035047426354140043,\n  0.0035437289625406265,\n  0.003513967152684927,\n  0.00351523794233799,\n  0.0035176363307982683,\n  0.0035363652277737856,\n  0.003499287646263838,\n  0.0034909050446003675,\n  0.0035012937150895596,\n  0.0035074851475656033,\n  0.0034905062057077885,\n  0.0034893956035375595,\n  0.003475162433460355,\n  0.003494704607874155,\n  0.0035083245020359755,\n  0.003519004210829735,\n  0.0034780867863446474,\n  0.003523667808622122,\n  0.0034680734388530254,\n  0.0035099692177027464,\n  0.00346135045401752,\n  0.003483828855678439,\n  0.003489917144179344,\n  0.0034944273065775633,\n  0.003498679492622614,\n  0.00361269642598927,\n  0.0036148130893707275,\n  0.003574288683012128,\n  0.0034822002053260803,\n  0.003469284623861313,\n  0.0034671653993427753,\n  0.0034619432408362627,\n  0.0034739323891699314,\n  0.0035191744100302458,\n  0.0035097014624625444,\n  0.0034985938109457493,\n  0.0034651674795895815,\n  0.003453887300565839,\n  0.003450032789260149,\n  0.003462526947259903,\n  0.0034988541156053543,\n  0.00345302140340209,\n  0.003450874937698245,\n  0.0034510858822613955,\n  0.003482318017631769,\n  0.003478802042081952,\n  0.0036965198814868927,\n  0.0035584433935582638,\n  0.003503617364913225,\n  0.0034936137963086367,\n  0.003463698085397482,\n  0.0034868246875703335,\n  0.00344216194935143,\n  0.003453110810369253,\n  0.0034344394225627184,\n  0.0034393533132970333,\n  0.0034413416869938374,\n  0.003449124749749899,\n  0.0034529187250882387,\n  0.0034558530896902084,\n  0.0035435031168162823,\n  0.0034392147790640593,\n  0.003437454579398036,\n  0.0034524824004620314,\n  0.003431921824812889,\n  0.003458981867879629,\n  0.0034398820716887712,\n  0.003479916602373123,\n  0.0034311567433178425,\n  0.0034889138769358397,\n  0.003431834978982806,\n  0.0034923688508570194,\n  0.003452856559306383,\n  0.0034492723643779755,\n  0.00342930993065238,\n  0.0034229725133627653],\n 'accuracy': [0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0],\n 'val_loss': [0.3766407370567322,\n  0.15563543140888214,\n  0.04757828265428543,\n  0.020004838705062866,\n  0.02143179439008236,\n  0.021699311211705208,\n  0.01897338591516018,\n  0.016967052593827248,\n  0.016196349635720253,\n  0.015700334683060646,\n  0.015307605266571045,\n  0.014946883544325829,\n  0.014469032175838947,\n  0.014177264645695686,\n  0.013765491545200348,\n  0.01338871568441391,\n  0.013081232085824013,\n  0.012751069851219654,\n  0.012418617494404316,\n  0.01217680610716343,\n  0.011957011185586452,\n  0.011717021465301514,\n  0.011447989381849766,\n  0.011188417673110962,\n  0.010957273654639721,\n  0.010810311883687973,\n  0.01061411015689373,\n  0.010402331128716469,\n  0.01020349096506834,\n  0.010037465021014214,\n  0.009868407621979713,\n  0.009727721102535725,\n  0.009545468725264072,\n  0.00938408449292183,\n  0.009295268915593624,\n  0.009123516269028187,\n  0.00898180715739727,\n  0.008845541626214981,\n  0.008753159083425999,\n  0.008587688207626343,\n  0.00846078246831894,\n  0.008360886946320534,\n  0.00826696865260601,\n  0.008140101097524166,\n  0.008053625002503395,\n  0.007977335713803768,\n  0.007833135314285755,\n  0.007741217501461506,\n  0.00764144491404295,\n  0.007563404738903046,\n  0.0074672214686870575,\n  0.007382821291685104,\n  0.007291226182132959,\n  0.007212138269096613,\n  0.007145469076931477,\n  0.007061189506202936,\n  0.007004797458648682,\n  0.006918758153915405,\n  0.006866720505058765,\n  0.006788680795580149,\n  0.006714935414493084,\n  0.006647302303463221,\n  0.006590394768863916,\n  0.006532160099595785,\n  0.006481942720711231,\n  0.006423007696866989,\n  0.006359695456922054,\n  0.006303124129772186,\n  0.006254835985600948,\n  0.0061971331015229225,\n  0.006157855037599802,\n  0.006108022294938564,\n  0.006052966229617596,\n  0.006010694894939661,\n  0.005960296373814344,\n  0.005942798685282469,\n  0.00587582029402256,\n  0.0058404384180903435,\n  0.005801177583634853,\n  0.005745461210608482,\n  0.005711308214813471,\n  0.0056844488717615604,\n  0.005635036155581474,\n  0.0055962251499295235,\n  0.005556793417781591,\n  0.005535582546144724,\n  0.00549949100241065,\n  0.005460768006742001,\n  0.0054663559421896935,\n  0.005402428098022938,\n  0.005367191042751074,\n  0.005350722931325436,\n  0.005330468527972698,\n  0.005283446051180363,\n  0.005247666500508785,\n  0.005229582078754902,\n  0.005239279940724373,\n  0.005167303141206503,\n  0.005141188390552998,\n  0.005112017504870892,\n  0.0051041413098573685,\n  0.005070018582046032,\n  0.0050370520912110806,\n  0.005019866395741701,\n  0.00501698162406683,\n  0.0049694799818098545,\n  0.00494150398299098,\n  0.0049718632362782955,\n  0.004918403923511505,\n  0.004888242110610008,\n  0.004874976351857185,\n  0.00484850350767374,\n  0.004860213492065668,\n  0.00481696892529726,\n  0.004803652875125408,\n  0.004774617962539196,\n  0.0047651855275034904,\n  0.004746653605252504,\n  0.004735019989311695,\n  0.004703265614807606,\n  0.004687241278588772,\n  0.004671401344239712,\n  0.004695523530244827,\n  0.00465106125921011,\n  0.004659854806959629,\n  0.004636473022401333,\n  0.004593550227582455,\n  0.004605398513376713,\n  0.004574998281896114,\n  0.004584984853863716,\n  0.004537387751042843,\n  0.004526680335402489,\n  0.004535405896604061,\n  0.00451135728508234,\n  0.0044752140529453754,\n  0.004511526320129633,\n  0.0044724647887051105,\n  0.004458250477910042,\n  0.004424175247550011,\n  0.004454619716852903,\n  0.004394181538373232,\n  0.004496356938034296,\n  0.004377433564513922,\n  0.004367264918982983,\n  0.004413589369505644,\n  0.004338852595537901,\n  0.00433981092646718,\n  0.004329134244471788,\n  0.004314396530389786,\n  0.0043192170560359955,\n  0.004299898631870747,\n  0.00427553616464138,\n  0.004300721921026707,\n  0.004238739609718323,\n  0.0042733484879136086,\n  0.00423393864184618,\n  0.004235878121107817,\n  0.004200637806206942,\n  0.004232869949191809,\n  0.00421541603282094,\n  0.004188305698335171,\n  0.004168360494077206,\n  0.004195683635771275,\n  0.004159631207585335,\n  0.004141630604863167,\n  0.004147232510149479,\n  0.004158572293817997,\n  0.004116323310881853,\n  0.004115016665309668,\n  0.004118732642382383,\n  0.004109327681362629,\n  0.004109141416847706,\n  0.004064800683408976,\n  0.0041234130039811134,\n  0.004064599983394146,\n  0.004055752418935299,\n  0.004100137390196323,\n  0.004035499878227711,\n  0.004065672867000103,\n  0.004029332660138607,\n  0.004016593098640442,\n  0.0040225256234407425,\n  0.004024631809443235,\n  0.004016044083982706,\n  0.004021624103188515,\n  0.00398967694491148,\n  0.004005406051874161,\n  0.003971070516854525,\n  0.004004620481282473,\n  0.003977110143750906,\n  0.003961903043091297,\n  0.003977004438638687,\n  0.00395539216697216,\n  0.003955299034714699,\n  0.003995154984295368,\n  0.003925140481442213,\n  0.0040275054052472115,\n  0.00391813600435853,\n  0.003932062536478043,\n  0.003942988347262144,\n  0.003916513174772263,\n  0.003909689839929342,\n  0.003910207189619541,\n  0.003906008554622531,\n  0.003907530568540096,\n  0.003882966935634613,\n  0.003945591859519482,\n  0.0038900759536772966,\n  0.0038971365429461002,\n  0.0038726585917174816,\n  0.0038696713745594025,\n  0.0038577497471123934,\n  0.003865649923682213,\n  0.0038627460598945618,\n  0.0038593499921262264,\n  0.0038542677648365498,\n  0.003866978455334902,\n  0.0038303672336041927,\n  0.003835421521216631,\n  0.0038944606203585863,\n  0.003823311999440193,\n  0.0038720346055924892,\n  0.0038174837827682495,\n  0.0038187745958566666,\n  0.003825051011517644,\n  0.0038502062670886517,\n  0.0038167093880474567,\n  0.003830412868410349,\n  0.0038149014580994844,\n  0.0038038778584450483,\n  0.003783019259572029,\n  0.0038004531525075436,\n  0.003810576628893614,\n  0.0037714086938649416,\n  0.003860160708427429,\n  0.0037854500114917755,\n  0.0038088031578809023,\n  0.003783382475376129,\n  0.0037775286473333836,\n  0.0038958131335675716,\n  0.0037701204419136047,\n  0.003918458241969347,\n  0.0037558693438768387,\n  0.0037712659686803818,\n  0.0037742177955806255,\n  0.0037459698505699635,\n  0.003822030033916235,\n  0.0037627604324370623,\n  0.003751564072445035,\n  0.0037429039366543293,\n  0.0037412955425679684,\n  0.0037530555855482817,\n  0.003738274099305272,\n  0.0037477202713489532,\n  0.003718757536262274,\n  0.0037428536452353,\n  0.003723036963492632,\n  0.0037579163908958435,\n  0.0037165475077927113,\n  0.0037269163876771927,\n  0.003719969419762492,\n  0.003727169707417488,\n  0.0037193973548710346,\n  0.003725589020177722,\n  0.0037291136104613543,\n  0.0037015024572610855,\n  0.003774403128772974,\n  0.003681749803945422,\n  0.0037810630165040493,\n  0.0036825642455369234,\n  0.003703867318108678,\n  0.0037051276303827763,\n  0.0036909959744662046,\n  0.0037086145021021366,\n  0.0036962435115128756,\n  0.003690341953188181,\n  0.003719890024513006,\n  0.0036679008044302464,\n  0.0036844159476459026,\n  0.003672343213111162,\n  0.0036843796260654926,\n  0.0036670230329036713,\n  0.003695524064823985,\n  0.003672119230031967,\n  0.003669205354526639,\n  0.003701360197737813,\n  0.0036562695167958736,\n  0.0036384128034114838,\n  0.003676024032756686,\n  0.003636715468019247,\n  0.003674446837976575,\n  0.0036508701741695404,\n  0.0036524892784655094,\n  0.0036719434428960085,\n  0.0036564539186656475,\n  0.0036444501020014286,\n  0.0036585889756679535,\n  0.0036296050529927015,\n  0.0037521407939493656,\n  0.003638631198555231,\n  0.0036401741672307253,\n  0.003657351713627577,\n  0.0036209500394761562,\n  0.003657879773527384,\n  0.0036132384557276964,\n  0.0036287824623286724,\n  0.0036426850128918886,\n  0.0036359280347824097,\n  0.003603205783292651,\n  0.003619731869548559,\n  0.003599638817831874,\n  0.003625818993896246,\n  0.0035926192067563534,\n  0.003690974088385701,\n  0.0035999473184347153,\n  0.003647850127890706,\n  0.003586848732084036,\n  0.0036006823647767305,\n  0.0035834978334605694,\n  0.0035931854508817196,\n  0.003584952326491475,\n  0.003616807283833623,\n  0.0035696052946150303,\n  0.003590129781514406,\n  0.003571131033822894,\n  0.0035746456123888493,\n  0.003591974498704076,\n  0.0035642660222947598,\n  0.00359712983481586,\n  0.0035553877241909504,\n  0.003556242911145091,\n  0.003556248266249895,\n  0.0035764642525464296,\n  0.003546640742570162,\n  0.0035849767737090588,\n  0.0035419557243585587,\n  0.0035677985288202763,\n  0.0035633021034300327,\n  0.0035539320670068264,\n  0.003565825056284666,\n  0.0035393654834479094,\n  0.0035566457081586123,\n  0.0035241208970546722,\n  0.003538950579240918,\n  0.0035354625433683395,\n  0.0035331198014318943,\n  0.003566531464457512,\n  0.0035215236712247133,\n  0.0036198855377733707,\n  0.0035159524995833635,\n  0.003515839111059904,\n  0.0035537753719836473,\n  0.003514838172122836,\n  0.003536440432071686,\n  0.0035434432793408632,\n  0.0035137024242430925,\n  0.003538578050211072,\n  0.0035218135453760624,\n  0.0035774502903223038,\n  0.003516153898090124,\n  0.0035352022387087345,\n  0.0035173967480659485,\n  0.0035434768069535494,\n  0.0035219998098909855,\n  0.003497349563986063,\n  0.0035472072195261717,\n  0.003494495525956154,\n  0.003509359899908304,\n  0.003508318215608597,\n  0.003487491514533758,\n  0.0035236210096627474,\n  0.003491149516776204,\n  0.00357653945684433,\n  0.0034907434601336718,\n  0.003514436539262533,\n  0.0034817226696759462,\n  0.0035208307672291994,\n  0.003483606968075037,\n  0.003484940156340599,\n  0.0034781217109411955,\n  0.003493626369163394,\n  0.003497661557048559,\n  0.0034885096829384565,\n  0.0035247784107923508,\n  0.0034811936784535646,\n  0.0034870170056819916,\n  0.003477690275758505,\n  0.003515640739351511,\n  0.0034652792382985353,\n  0.003533355426043272,\n  0.003471365664154291,\n  0.0034918934106826782,\n  0.003481656778603792,\n  0.0034741885028779507,\n  0.0035274121910333633,\n  0.0034888810478150845,\n  0.003516135737299919,\n  0.003477157326415181,\n  0.0035767280496656895,\n  0.00346558541059494,\n  0.0034773373045027256,\n  0.003460996551439166,\n  0.0034599960781633854,\n  0.003461898537352681,\n  0.0034791200887411833,\n  0.003565291641280055,\n  0.003538361983373761,\n  0.003559795441105962,\n  0.003471503732725978,\n  0.00346861663274467,\n  0.003460933919996023,\n  0.0034716720692813396,\n  0.0035258247517049313,\n  0.0034632571041584015,\n  0.0035101708490401506,\n  0.0034582368098199368,\n  0.0035657223779708147,\n  0.003462945343926549,\n  0.00347033585421741,\n  0.0034734017681330442,\n  0.003498038975521922,\n  0.003459323663264513,\n  0.0034633271861821413,\n  0.003468162612989545,\n  0.0034602792002260685,\n  0.003550442634150386,\n  0.0034569264389574528,\n  0.003461382817476988,\n  0.0034958445467054844,\n  0.003475446254014969,\n  0.00348082697018981,\n  0.0034529739059507847,\n  0.0034969442058354616,\n  0.0034561126958578825,\n  0.0034546174574643373,\n  0.003476123558357358,\n  0.0034485217183828354,\n  0.003481136169284582,\n  0.0034604021348059177,\n  0.003553895279765129,\n  0.0034669400192797184,\n  0.003480537561699748,\n  0.00345142325386405,\n  0.0035284250043332577,\n  0.003451709169894457,\n  0.0034513785503804684,\n  0.003479349659755826,\n  0.0034681898541748524,\n  0.003511124523356557,\n  0.0036610737442970276,\n  0.0037333047948777676,\n  0.00347680551931262,\n  0.0034670070745050907,\n  0.003455363679677248,\n  0.003455948084592819,\n  0.0034694999922066927,\n  0.0034596144687384367,\n  0.003451519412919879,\n  0.0034926619846373796,\n  0.0035280250012874603,\n  0.0034490551333874464,\n  0.0034567874390631914,\n  0.0034617576748132706,\n  0.0034472174011170864,\n  0.003462608437985182,\n  0.0034391512162983418,\n  0.0034504239447414875,\n  0.0034510798286646605,\n  0.003588608233258128,\n  0.0036176536232233047,\n  0.0037221028469502926,\n  0.0034532092977315187,\n  0.0034443377517163754,\n  0.003573659108951688,\n  0.003474463475868106,\n  0.0034515627194195986,\n  0.003472510725259781,\n  0.0034546293318271637,\n  0.0034535813611000776,\n  0.0034498702734708786,\n  0.003448947099968791,\n  0.003513745265081525,\n  0.0034463286865502596,\n  0.0036713951267302036,\n  0.0034627902787178755,\n  0.003486722009256482,\n  0.003447523806244135,\n  0.003494859440252185,\n  0.0034528994001448154,\n  0.0034376848489046097,\n  0.0034622191451489925,\n  0.003460140433162451,\n  0.0034513608552515507,\n  0.003492593765258789,\n  0.0034756618551909924,\n  0.0035030990839004517,\n  0.0035194382071495056,\n  0.003447389928624034,\n  0.003445221809670329,\n  0.003441006410866976],\n 'val_accuracy': [0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0]}"},"metadata":{}}]},{"cell_type":"code","source":"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:19:31.800207Z","iopub.execute_input":"2023-07-01T17:19:31.800881Z","iopub.status.idle":"2023-07-01T17:19:32.067232Z","shell.execute_reply.started":"2023-07-01T17:19:31.800849Z","shell.execute_reply":"2023-07-01T17:19:32.066180Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x79f8117dd660>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsFklEQVR4nO3dfXBc5WHv8d85u9JKyNKCsS3bWDaCgDEWEJBTIxOHJE6Ua0gy3HSmTkgNuYUUFczgqEyL42ntejIj7m1KTGaQgxsCddOAJ9ckw22cBHUCxuCkKUJuDLiOGwxyjISQA1r5Tavd89w/9kW7lmS0srSP7ef7mTms9uzZs88+K7w/PW/HM8YYAQAAWOLbLgAAAHAbYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVWHbBRiLIAj09ttvq7KyUp7n2S4OAAAYA2OM+vv7NXv2bPn+6O0fZ0UYefvtt1VTU2O7GAAAYBwOHjyoOXPmjPr4WRFGKisrJaXeTFVVleXSAACAsYjFYqqpqcl+j4/mrAgjma6ZqqoqwggAAGeZDxpiwQBWAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVWfFhfImy/9t/71ePdSn/1E3U9dfcqHt4gAA4CSnW0Z2/PZdPbHrTb3+dsx2UQAAcJbTYSRzQePAGKvlAADAZU6HEd/74GMAAMDkcjqMeF4qjdAyAgCAPW6HkfQtWQQAAHvcDiPZlhHLBQEAwGGOh5HUrRFpBAAAW5wOI5kBrHTTAABgj9NhxEuPGjGkEQAArHE6jPjpd08WAQDAHqfDSGY+DQNYAQCwZ1xhpLW1VbW1tSorK1N9fb127tw56rHPP/+8PM8btv3Xf/3XuAs9UXwGsAIAYF3BYWTr1q1avXq11q5dq46ODi1dulTLly9XZ2fnKZ+3b98+dXV1ZbfLLrts3IWeKJnZNLSMAABgT8Fh5KGHHtIdd9yhO++8UwsWLNDGjRtVU1OjTZs2nfJ5M2bM0MyZM7NbKBQad6EnSmYAK4NGAACwp6AwEo/H1d7ersbGxrz9jY2N2rVr1ymfe+2112rWrFlatmyZnnvuuVMeOzAwoFgslrdNhqFuGgAAYEtBYaS3t1fJZFLV1dV5+6urq9Xd3T3ic2bNmqXNmzdr27ZtevrppzV//nwtW7ZML7zwwqiv09LSomg0mt1qamoKKeaYcW0aAADsC4/nSZkv8QxjzLB9GfPnz9f8+fOz9xsaGnTw4EF985vf1Mc+9rERn7NmzRo1Nzdn78disUkJJB69NAAAWFdQy8i0adMUCoWGtYL09PQMay05leuvv1779+8f9fFIJKKqqqq8bTJ4TO0FAMC6gsJIaWmp6uvr1dbWlre/ra1NS5YsGfN5Ojo6NGvWrEJeelIwtRcAAPsK7qZpbm7WypUrtWjRIjU0NGjz5s3q7OxUU1OTpFQXy6FDh7RlyxZJ0saNG3XxxRdr4cKFisfj+v73v69t27Zp27ZtE/tOxoFuGgAA7Cs4jKxYsUKHDx/Whg0b1NXVpbq6Om3fvl3z5s2TJHV1deWtORKPx3X//ffr0KFDKi8v18KFC/WTn/xEN91008S9i3HyPa5NAwCAbZ45C76JY7GYotGo+vr6JnT8SMtP9+rRHW/ojo/W6m8+e+WEnRcAAIz9+9vpa9MMXbXXckEAAHCY02GEAawAANjndBhhACsAAPY5HUYYwAoAgH1Oh5HMmrEsegYAgD1uh5FMywhjRgAAsMbxMJK6pWUEAAB73A4jTO0FAMA6p8OIn73QMGkEAABbnA4j2W6awG45AABwmeNhhAGsAADY5ngYSd0ygBUAAHucDiNDi55ZLggAAA5zOoxkxq+yAisAAPY4HUayLSOWywEAgMucDiNDY0aIIwAA2OJ0GMkgiwAAYI/TYYRuGgAA7HM6jNBNAwCAfU6HkUzLCE0jAADY43QYoWUEAAD7HA8jLHoGAIBtboeR9C0tIwAA2ON2GGHICAAA1jkdRoauTUMcAQDAFqfDyNC1aawWAwAApzkdRlj0DAAA+5wOI2JqLwAA1jkdRnym9gIAYJ3TYYSpvQAA2Od0GPGdfvcAAJwZnP469tJtI7SMAABgj9thJLPoGVkEAABrHA8jDGAFAMA2t8NI+pZuGgAA7HE6jLDoGQAA9jkdRobGjBBHAACwxekw4jOAFQAA65wOI2JqLwAA1jkdRrItI3aLAQCA05wOI5mpvQFpBAAAa9wOI5kf6KYBAMAap8NI5to0RBEAAOxxOoxwbRoAAOxzO4wwtRcAAOscDyMMYAUAwDanw4jPCqwAAFjndBjJjBkhiwAAYI/bYSS76BlpBAAAWwgjomUEAACb3A4jTO0FAMA6p8MI16YBAMA+p8NIZmovDSMAANjjdBhhai8AAPaNK4y0traqtrZWZWVlqq+v186dO8f0vJdeeknhcFgf/vCHx/OyEy4zgJVFzwAAsKfgMLJ161atXr1aa9euVUdHh5YuXarly5ers7PzlM/r6+vTbbfdpmXLlo27sBMt203DqBEAAKwpOIw89NBDuuOOO3TnnXdqwYIF2rhxo2pqarRp06ZTPu+uu+7SrbfeqoaGhnEXdqKlG0YUBFaLAQCA0woKI/F4XO3t7WpsbMzb39jYqF27do36vMcff1y/+93vtG7dujG9zsDAgGKxWN42GTItIwAAwJ6Cwkhvb6+SyaSqq6vz9ldXV6u7u3vE5+zfv18PPPCA/uVf/kXhcHhMr9PS0qJoNJrdampqCinmmDGAFQAA+8Y1gPXkFgVjzIitDMlkUrfeeqv+7u/+TpdffvmYz79mzRr19fVlt4MHD46nmB9oaNGzSTk9AAAYg7E1VaRNmzZNoVBoWCtIT0/PsNYSServ79fLL7+sjo4OrVq1SpIUBIGMMQqHw3r22Wf1yU9+ctjzIpGIIpFIIUUbF65NAwCAfQW1jJSWlqq+vl5tbW15+9va2rRkyZJhx1dVVWnPnj3avXt3dmtqatL8+fO1e/duLV68+PRKf5qY2gsAgH0FtYxIUnNzs1auXKlFixapoaFBmzdvVmdnp5qamiSlulgOHTqkLVu2yPd91dXV5T1/xowZKisrG7bfBp8VWAEAsK7gMLJixQodPnxYGzZsUFdXl+rq6rR9+3bNmzdPktTV1fWBa46cKTwGsAIAYJ1nzoJv4lgspmg0qr6+PlVVVU3Yefd19+szG1/Q1IpSvfI3n56w8wIAgLF/f3NtGtEyAgCATU6HEQawAgBgn+NhJDOAlTQCAIAtboeR9C1ZBAAAe5wOI9mpvZbLAQCAy5wOI0NjRogjAADY4nQYCR/r0SXe26oyR2wXBQAAZzkdRi54YZ1+Eblfn9MO20UBAMBZTocReW6/fQAAzgRufxv7qbfvM4QVAABr3A4jmcm9JrBbDAAAHOZ0GPHSLSMeLSMAAFjjdBgZWvaMlhEAAGxxO4ykB7B6NIwAAGCN02FkqJsm4Po0AABY4nQYyXTT+DJcnwYAAEucDiOeNzSAlSXhAQCww+kwkrvOCFEEAAA73A4j6Svl+R7dNAAA2OJ0GPGyy8HTTQMAgC1Oh5FsywidNAAAWON0GGEAKwAA9hFGxNReAABscjqM5HbT0DICAIAdjoeRoQGsRBEAAOxwOox4HiuwAgBgm9NhRDkDWLk2DQAAdjgdRjw/JImWEQAAbHI7jGQvlBcwgBUAAEucDiOZa9NIYgArAACWOB1GhtYZoWUEAABbnA4jecvBk0UAALDC8TCSuxy85bIAAOAot8OIctYZoWkEAAAr3A4juSuwkkUAALDC8TDCtWkAALCNMCIWPQMAwCbHw0jucvCWywIAgKPcDiOZAaweA1gBALDF7TCSM4CVqb0AANhBGFFmzAhpBAAAGxwPI7nrjAAAABscDyO5A1iJIwAA2EAYEVN7AQCwye0wkp5N4ylgACsAAJa4HUa8TBgRo0YAALCEMKL0cvCB5bIAAOAox8NIzgBWWkYAALCCMCIGsAIAYJPbYSRnACthBAAAO9wOI9luGgawAgBgi+NhJDOAlam9AADY4ngY4do0AADYNq4w0traqtraWpWVlam+vl47d+4c9dgXX3xRN9xwgy688EKVl5friiuu0Le+9a1xF3hC5cymoWUEAAA7woU+YevWrVq9erVaW1t1ww036NFHH9Xy5cv1+uuva+7cucOOr6io0KpVq3T11VeroqJCL774ou666y5VVFToz//8zyfkTYxfZgCrkRgzAgCAFZ4psH9i8eLFuu6667Rp06bsvgULFuiWW25RS0vLmM7xhS98QRUVFfrnf/7nMR0fi8UUjUbV19enqqqqQop7ar/5ofT0nXoxuVCRO/5VH7l46sSdGwAAx431+7ugbpp4PK729nY1Njbm7W9sbNSuXbvGdI6Ojg7t2rVLN954YyEvPTlyVmBlyAgAAHYU1E3T29urZDKp6urqvP3V1dXq7u4+5XPnzJmjd999V4lEQuvXr9edd9456rEDAwMaGBjI3o/FYoUUc+wyYcQzCkgjAABYMa4BrF76SzzDGDNs38l27typl19+Wd/5zne0ceNGPfnkk6Me29LSomg0mt1qamrGU8wPlrscPFkEAAArCmoZmTZtmkKh0LBWkJ6enmGtJSerra2VJF111VV65513tH79en3pS18a8dg1a9aoubk5ez8Wi01SIBkawMqiZwAA2FFQy0hpaanq6+vV1taWt7+trU1LliwZ83mMMXndMCeLRCKqqqrK2yYFLSMAAFhX8NTe5uZmrVy5UosWLVJDQ4M2b96szs5ONTU1SUq1ahw6dEhbtmyRJD3yyCOaO3eurrjiCkmpdUe++c1v6t57753AtzFOXCgPAADrCg4jK1as0OHDh7VhwwZ1dXWprq5O27dv17x58yRJXV1d6uzszB4fBIHWrFmjAwcOKBwO69JLL9WDDz6ou+66a+LexXjlzKZhACsAAHYUvM6IDZO2zsi+n0pPflG7g0vV96c/142XT5+4cwMA4LhJWWfknJO3HPwZn8kAADgnuR1GNHTVXibTAABgh9thJNsyIqb2AgBgieNhJHXjyygI7BYFAABXOR5GctYZsVwUAABcRRgRA1gBALDJ7TCSM4CVLAIAgB1uh5HcAaykEQAArHA8jOS0jFguCgAArnI8jAy9fcaMAABgB2FEqZaRgCwCAIAVbocRDV0ojzEjAADY4XYYyV1nhCwCAIAVhBFJvsc6IwAA2OJ4GMncGMaMAABgieNhJGcFVtIIAABWuB1Gcgaw0k0DAIAdboeRvGvTWC4LAACOIoyIlhEAAGxyPIykumk81hkBAMAax8MI3TQAANjmdhhhACsAANa5HUZoGQEAwDrCiNItI6QRAACscDyMDA1gpZsGAAA7CCOimwYAAJscDyOsMwIAgG1uh5HsbJqAdUYAALDE7TCSnU0jumkAALDE8TCSGTMS0E0DAIAljoeRnJYRmkYAALCCMKLUmBGyCAAAdrgdRtIDWEMes2kAALDF7TDiDb19umkAALDD8TDiZX80JrBYEAAA3OV4GBl6+8YkLRYEAAB3OR5GclpGaBgBAMAKt8OIcrtpaBkBAMAGt8NIbjdNQNMIAAA2EEbSuDYNAAB2OB5GcseM0E0DAIANjoeRnHVGaBgBAMAKt8NIzgBWMYAVAAAr3A4jeWNGGMAKAIANhJE0Qz8NAABWOB5GcrppGMAKAIAVjoeR3AGstIwAAGCD42EkdwArY0YAALDB7TAiyaRn1DCAFQAAOwgjma4aumkAALDC+TAiWkYAALDK+TBCNw0AAHYRRtLdNEGSbhoAAGxwPoxkumk8loMHAMCKcYWR1tZW1dbWqqysTPX19dq5c+eoxz799NP69Kc/renTp6uqqkoNDQ36+c9/Pu4CTzTjZbppaBkBAMCGgsPI1q1btXr1aq1du1YdHR1aunSpli9frs7OzhGPf+GFF/TpT39a27dvV3t7uz7xiU/oc5/7nDo6Ok678BODMSMAANjkmQKbBBYvXqzrrrtOmzZtyu5bsGCBbrnlFrW0tIzpHAsXLtSKFSv0t3/7t2M6PhaLKRqNqq+vT1VVVYUU9wMNfuMilSSO6P6Zj+ubTV+Y0HMDAOCysX5/F9QyEo/H1d7ersbGxrz9jY2N2rVr15jOEQSB+vv7NXXq1FGPGRgYUCwWy9smS2YAq0fLCAAAVhQURnp7e5VMJlVdXZ23v7q6Wt3d3WM6xz/8wz/o6NGj+pM/+ZNRj2lpaVE0Gs1uNTU1hRSzQHTTAABg07gGsHq513RRavDnyftG8uSTT2r9+vXaunWrZsyYMepxa9asUV9fX3Y7ePDgeIo5Nh5hBAAAm8KFHDxt2jSFQqFhrSA9PT3DWktOtnXrVt1xxx364Q9/qE996lOnPDYSiSgSiRRStHHLLgcfMJsGAAAbCmoZKS0tVX19vdra2vL2t7W1acmSJaM+78knn9RXvvIV/eAHP9DNN988vpJOmnSLDi0jAABYUVDLiCQ1Nzdr5cqVWrRokRoaGrR582Z1dnaqqalJUqqL5dChQ9qyZYukVBC57bbb9PDDD+v666/PtqqUl5crGo1O4FsZp3TLCN00AADYUXAYWbFihQ4fPqwNGzaoq6tLdXV12r59u+bNmydJ6urqyltz5NFHH1UikdA999yje+65J7v/9ttv1xNPPHH67+C0segZAAA2FbzOiA2Tuc7Iif99ucqOv6Ovnf+wvrX6KxN6bgAAXDYp64yckzIDWM/8TAYAwDmJMJIdwMqF8gAAsIEwkm4ZCZjaCwCAFYSR9KJnHt00AABY4XwYMazACgCAVc6HkWwVEEYAALCCMJLpphHdNAAA2EAYYQVWAACsIoywzggAAFYRRrhQHgAAVhFG6KYBAMAqwoiXaRmhmwYAABsIIx5TewEAsIkwwgBWAACscj6MeNl1RmgZAQDABufDiLLLwdMyAgCADYQRloMHAMAqwkh6zIhHGAEAwArCiE83DQAANjkfRjyxzggAADY5H0ayU3uZTQMAgBWEET9VBT5jRgAAsML5MOLRMgIAgFXOhxF5odQNLSMAAFhBGPHDqRsTMKMGAAALCCN+qmUk5CWZUAMAgAXOhxEvE0YUKCCNAABQdM6HkUw3TSqMWC4LAAAOIozQMgIAgFXOh5HcbhqyCAAAxUcYSYcRn5YRAACscD6M5I8ZIYwAAFBszoeRoW6apALWPQMAoOicDyMMYAUAwC7nw4iX6abxCCMAANhAGMlrGbFcGAAAHOR8GMlcKC81tZc0AgBAsRFG8qb2Wi4LAAAOIoykw0hYScaMAABgAWEkp5smSdMIAABFRxhJz6bxWQ4eAAArCCOsMwIAgFWEEY8wAgCATYQR1hkBAMAqwkgmjHisMwIAgA2EES/nQnlkEQAAio4wkrk2DVN7AQCwgjCStwIrYQQAgGIjjHipKgizzggAAFYQRmgZAQDAKsJIzpgRwggAAMVHGPFyL5RnuSwAADiIMJLTTcM6IwAAFB9hJLsCq2FqLwAAFowrjLS2tqq2tlZlZWWqr6/Xzp07Rz22q6tLt956q+bPny/f97V69erxlnVypLtpfC9QgjACAEDRFRxGtm7dqtWrV2vt2rXq6OjQ0qVLtXz5cnV2do54/MDAgKZPn661a9fqmmuuOe0CTzh/aMzIYDKwXBgAANxTcBh56KGHdMcdd+jOO+/UggULtHHjRtXU1GjTpk0jHn/xxRfr4Ycf1m233aZoNHraBZ5wObNpEklaRgAAKLaCwkg8Hld7e7saGxvz9jc2NmrXrl0TVqiBgQHFYrG8bdJ4QwNYEwEtIwAAFFtBYaS3t1fJZFLV1dV5+6urq9Xd3T1hhWppaVE0Gs1uNTU1E3buYfyhFVgHaRkBAKDoxjWA1fO8vPvGmGH7TseaNWvU19eX3Q4ePDhh5x4m3U1DywgAAHaECzl42rRpCoVCw1pBenp6hrWWnI5IJKJIJDJh5zslLzO1N9BggpYRAACKraCWkdLSUtXX16utrS1vf1tbm5YsWTKhBSua7DojSQ3SMgIAQNEV1DIiSc3NzVq5cqUWLVqkhoYGbd68WZ2dnWpqapKU6mI5dOiQtmzZkn3O7t27JUlHjhzRu+++q927d6u0tFRXXnnlxLyL08FsGgAArCo4jKxYsUKHDx/Whg0b1NXVpbq6Om3fvl3z5s2TlFrk7OQ1R6699trsz+3t7frBD36gefPm6c033zy90k+ETDeNF7DOCAAAFhQcRiTp7rvv1t133z3iY0888cSwfWf0NV/Ss2lSA1jP4HICAHCO4to06W6asAIlaBkBAKDoCCM5i56xzggAAMVHGPGHpvayzggAAMVHGPGGpvYymwYAgOIjjOS0jMQZMwIAQNERRnK7aWgZAQCg6AgjHmNGAACwiTCSswIrs2kAACg+wki6m8b3jBKJpOXCAADgHsKIN1QFyYAwAgBAsRFG/KEV8YPEoMWCAADgJsJIuptGkoJkwmJBAABwE2HEGwojCcIIAABFRxjJ6aYxhBEAAIqOMJLTTWMCwggAAMVGGPE8GXmSpGSS2TQAABQbYUSSSXfV0E0DAEDxEUYkmfRaI4Z1RgAAKDrCiJSdUcPUXgAAio8wIsmkB7EygBUAgOIjjEhDLSNcmwYAgKIjjEjZMGIMYQQAgGIjjEjZtUaYTQMAQPERRqShhc+YTQMAQNERRqShMSMMYAUAoOgIIxItIwAAWEQYkYYulhckZYyxWxYAABxDGJHkhcskSWVeXImAMAIAQDERRiQpMkWSVKETSiQJIwAAFBNhRJKXDiNTvOOKJwPLpQEAwC2EEUlepFJSpmWEMAIAQDERRjTUMlKh44wZAQCgyAgjklSaahmZ4p3QIC0jAAAUFWFEyhnAelzxBGEEAIBiIoxIUmlmAOsJHT4at1wYAADcQhiR8qb2dvWdsFwYAADcQhiRsmNGKnRc3X3HLRcGAAC3EEakbMvIFI+WEQAAio0wImXHjFTouN6JEUYAACgmwog0NGaElhEAAIqOMCINzabRcb32dkwBC58BAFA0hBEpp5vmhOKJpJY9tENv9h61XCgAANxAGJGy3TRhL9At/kvyD/9Wf/rYv6vv+KDlggEAcO4jjEjZlhFJ2ljaqh9H1qv/vXf11S0v69D7TPUFAGAyEUYkyQ/l3a3UUd0T2a5fH/iDbvw/z6l56251dL4nYxhLAgDARPPMWfANG4vFFI1G1dfXp6qqqsl5kV+2Sj2vSRcvlX50l4xfqq9f+C09efCC7CFXzKzUio/U6H9ee5HOP690csoBAMA5Yqzf34SRkxkjPflF6bc/k0rO0+FLPq+nj35YrW/O1HuJVAApCXm64UPTdNNVs/SpBdWaWkEwAQDgZISR03HkXWnrl6WD/57dZfyweiuv1HMDl+tfY5fq5WC+jqlMniddPed83Xj5dH18/nRdM+d8hXxv8ssIAMAZjjByuoyRDuyQ9v4/6bc/l/oO5j0cKKR9oQ/puYH5+vdggfYGc9Wj81VVVqJr516g6+ZeoGvnnq8Pz03tAwDANYSRifbeW9KbL6a2t16U3u8cdsgxRfRGMEtvmFk6YGbpd8EsvalZikcv0UXVM/ShGVN06YwpumzGFF0yfYqi5YQUAMC5izAy2d57S3rrJenNl6SDv5L+cEAyyVEP7zHn64CZqXfMBXrXnK93TVRHSqbKn1Kt0vNnacq02bpwxmzNmVqpiy4o1/QpEUXLS+TT5QMAOEsRRootEZfef0vq3S8d3i8d/m+p978V9O6Xf+zdMZ0iaTz9QVXqNVG9a6Lq1fk6XnK+TMkUeWWVCpVXqqS8SpGKKpVXRHVe5fnpLarKqvNVVRlVeWlYnkeAAQDYN9bv73ARy3RuC5dK0y5LbTl8STr+vvSH36VaT468Ix15R4N93Yq/362gv1vh470qi/9BIc9ouvo03evTgswJAkkD6a3v1EVIGk9HVKbjXrlOeOU64Z+nAf88xUPnaTB0ngbDFUqEK5QsqVBQUiFTOiW14FtkirzIFIVLylQSKVdJJKKS0vNUUlau0tIyRcrKVVZerrLSiMpKQoqEfVpsAAAThjBSDOXnSxfVp7a0kvSWlUxIxw6nwsrRHiX63tHx997WQOxdxY/1K3EiJnOiX4ofkR8/qnDiqEqDYyoLjqlcJ+TLKOQZVeq4KnVcMpKS6W2CVrVPGF9xlSimsOIqUcILK6mwEgop6YWV9EIKvHD65xIFXji1+bk/h2W80NCWvi8/JOOFs/c9P/WY/NTP8nx5Xkie78vzfSn7c+pxz/Pl+77kh1K3ni8/FJbv+6nHQuG841Pn84d+Tj83sy9zrOTLC4Xk+yF5oRJ5obB8PyTf9+R7vvyQL99L3ZfnpZ4nL10mT74fyu73M/s8T17q8NTPUs4+Qh4A94wrjLS2turv//7v1dXVpYULF2rjxo1aunTpqMfv2LFDzc3Neu211zR79mz91V/9lZqamsZd6HNSKCxVVqc2pT6YyvT2gYJAZvCojh3p05FYn471v69jR/qUTAeYYOCINHBEivfLix+VP3hE4cGjCiWOKpw4ptLkMZUExxQKBlVi4gqbuMJmUCVKKKQg+zJhL1BYAzpPA8PLYNIbPlDC+AqUCiFSqtoG5UnyFKS3kZwqpsRVorhKUh9BOtAYeTkfiSeTPkOQfi2TfS0v/fH5MunnZp459CzlnC3zWO6Z8z/8zP1AvuIqVYkSOuJVZMuWKV/mPOakd+eN8BryJM8YSZ48b+j1UucfVKCQEl542LmUd6aR747tOWM4JrMvZ3f+OzEK5CuQr6QXkpE/7Ay5L5PpRDeSBpOZ/xfTwTd78PD7Xma/lP1McxmjYZ/ZyWUI5Txt+Od78js++Vy5v3nDXj3/uek3mdl78m9t7hlG+z0b+fiTP9X0fW+0T+2k92BOLsfoch83RvKCuE545eoPT039MZT+48Pz/NSRmfec+dzk5f96mUDlySMKD8Z0woR1NFKtUOYAL/uf3B8lSZWJPyjhlWogVJFTtqFjvPRLG0mByfyupX5fPM/T1Bv+lz704dG/yydTwWFk69atWr16tVpbW3XDDTfo0Ucf1fLly/X6669r7ty5w44/cOCAbrrpJn31q1/V97//fb300ku6++67NX36dP3xH//xhLwJ5/m+vEilKiKVqrhwzsSeO5mQEiekZFyJ+HENDJxQ/MRxDZw4psRgXMnEoJKJuILEoIJEXMlEXCb9c5BM3ZpEXAoGpWRCJkjICxJSdkumBv6mf/aChDyTkExSXvq+TCApkIyRFyQlk/rKlgnkmZxbBfJz7nvK3Bp5Jpm+TX0VeDLy0/t8GfnKPG4Uyvwso1D2qyNQSEmVaPRBymMV9oIPPqhAIwbE8ZjMQElYBcanSJdIe/nQEslSGCl4AOvixYt13XXXadOmTdl9CxYs0C233KKWlpZhx//1X/+1nnnmGe3duze7r6mpSf/5n/+pX/7yl2N6zbNiACvcYUz6L5v0rQnSPwcyJpAJTOrWBDLGKAgCmSB1TJBMhSsTJFORKJCMjAJjpCCpIAikIDnUBmGGGp2Mcv5SzrtNSom4vORA+hiTuo6SkZRu2TLGpO8aGRkpXZ7UccnUX3Pp8g61fwy1S6Ru8u+b7F9kox9nknEpcUJJr0R+vD/1PnPfQPqVhu6m/rJNN4AMtc/k3jc5r28kP3FcQSiSCqHBUJ/kyf+0pe7mN+F5Ocfk/sU6dD/v3gjnHP6X+VBrhsm7nxHy0iHZJCWT/jzMSSUz+X/Ve55UXhqSL6Xq0BgFRunfudS+1GcXZH+nlPk9SJcr9SHntjIM/TfzY+ZVk8Yomcw//qSqGKHFZfT7w1qeRuuO9Ia3lI3SvjF0/+QGjcy5Tf7xJvOJ5D7BO/W589/DyQ+NfKzneSoJl6gsGVM4HlMQpD6fIP1ZZZ+a+7uWaSnJNuz4ioenyJRFVeUdl44dVjIw+WUwJ9+XToSr5Ju4Qsnhf5xkfr89LzWW0fcy/6aY9L8zRjOvX6FL6hYPe+7pmJQBrPF4XO3t7XrggQfy9jc2NmrXrl0jPueXv/ylGhsb8/Z95jOf0WOPPabBwUGVlAxfa2NgYEADA0OVGYvFCikmMLkyAz5Gekin7k4BAAxX0FV7e3t7lUwmVV1dnbe/urpa3d3dIz6nu7t7xOMTiYR6e3tHfE5LS4ui0Wh2q6mpKaSYAADgLFJQGMk4ecS/MeaUswBGOn6k/Rlr1qxRX19fdjt48OCIxwEAgLNfQd0006ZNUygUGtYK0tPTM6z1I2PmzJkjHh8Oh3XhhReO+JxIJKJIJFJI0QAAwFmqoJaR0tJS1dfXq62tLW9/W1ublixZMuJzGhoahh3/7LPPatGiRSOOFwEAAG4puJumublZ3/3ud/W9731Pe/fu1de+9jV1dnZm1w1Zs2aNbrvttuzxTU1Neuutt9Tc3Ky9e/fqe9/7nh577DHdf//9E/cuAADAWavgdUZWrFihw4cPa8OGDerq6lJdXZ22b9+uefPmSZK6urrU2Tl0Rdva2lpt375dX/va1/TII49o9uzZ+va3v80aIwAAQBIXygMAAJNkrN/f45pNAwAAMFEIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAqoLXGbEhM/uYq/cCAHD2yHxvf9AqImdFGOnv75ckrt4LAMBZqL+/X9FodNTHz4pFz4Ig0Ntvv63KyspTXh24ULFYTDU1NTp48CCLqU0y6ro4qOfioJ6Lh7oujsmqZ2OM+vv7NXv2bPn+6CNDzoqWEd/3NWfOnEk7f1VVFb/kRUJdFwf1XBzUc/FQ18UxGfV8qhaRDAawAgAAqwgjAADAKqfDSCQS0bp16xSJRGwX5ZxHXRcH9Vwc1HPxUNfFYbuez4oBrAAA4NzldMsIAACwjzACAACsIowAAACrCCMAAMAqp8NIa2uramtrVVZWpvr6eu3cudN2kc4qL7zwgj73uc9p9uzZ8jxPP/7xj/MeN8Zo/fr1mj17tsrLy/Xxj39cr732Wt4xAwMDuvfeezVt2jRVVFTo85//vH7/+98X8V2c+VpaWvSRj3xElZWVmjFjhm655Rbt27cv7xjq+vRt2rRJV199dXbRp4aGBv30pz/NPk4dT46WlhZ5nqfVq1dn91HXE2P9+vXyPC9vmzlzZvbxM6qejaOeeuopU1JSYv7xH//RvP766+a+++4zFRUV5q233rJdtLPG9u3bzdq1a822bduMJPOjH/0o7/EHH3zQVFZWmm3btpk9e/aYFStWmFmzZplYLJY9pqmpyVx00UWmra3NvPLKK+YTn/iEueaaa0wikSjyuzlzfeYznzGPP/64efXVV83u3bvNzTffbObOnWuOHDmSPYa6Pn3PPPOM+clPfmL27dtn9u3bZ77+9a+bkpIS8+qrrxpjqOPJ8Otf/9pcfPHF5uqrrzb33Xdfdj91PTHWrVtnFi5caLq6urJbT09P9vEzqZ6dDSN/9Ed/ZJqamvL2XXHFFeaBBx6wVKKz28lhJAgCM3PmTPPggw9m9504ccJEo1Hzne98xxhjzPvvv29KSkrMU089lT3m0KFDxvd987Of/axoZT/b9PT0GElmx44dxhjqejJdcMEF5rvf/S51PAn6+/vNZZddZtra2syNN96YDSPU9cRZt26dueaaa0Z87EyrZye7aeLxuNrb29XY2Ji3v7GxUbt27bJUqnPLgQMH1N3dnVfHkUhEN954Y7aO29vbNTg4mHfM7NmzVVdXx+dwCn19fZKkqVOnSqKuJ0MymdRTTz2lo0ePqqGhgTqeBPfcc49uvvlmfepTn8rbT11PrP3792v27Nmqra3VF7/4Rb3xxhuSzrx6PisulDfRent7lUwmVV1dnbe/urpa3d3dlkp1bsnU40h1/NZbb2WPKS0t1QUXXDDsGD6HkRlj1NzcrI9+9KOqq6uTRF1PpD179qihoUEnTpzQlClT9KMf/UhXXnll9h9e6nhiPPXUU3rllVf0H//xH8Me4/d54ixevFhbtmzR5ZdfrnfeeUff+MY3tGTJEr322mtnXD07GUYyPM/Lu2+MGbYPp2c8dcznMLpVq1bpN7/5jV588cVhj1HXp2/+/PnavXu33n//fW3btk233367duzYkX2cOj59Bw8e1H333adnn31WZWVlox5HXZ++5cuXZ3++6qqr1NDQoEsvvVT/9E//pOuvv17SmVPPTnbTTJs2TaFQaFiy6+npGZYSMT6ZEdunquOZM2cqHo/rvffeG/UYDLn33nv1zDPP6LnnntOcOXOy+6nriVNaWqoPfehDWrRokVpaWnTNNdfo4Ycfpo4nUHt7u3p6elRfX69wOKxwOKwdO3bo29/+tsLhcLauqOuJV1FRoauuukr79+8/436nnQwjpaWlqq+vV1tbW97+trY2LVmyxFKpzi21tbWaOXNmXh3H43Ht2LEjW8f19fUqKSnJO6arq0uvvvoqn0MOY4xWrVqlp59+Wr/4xS9UW1ub9zh1PXmMMRoYGKCOJ9CyZcu0Z88e7d69O7stWrRIX/7yl7V7925dcskl1PUkGRgY0N69ezVr1qwz73d6QofDnkUyU3sfe+wx8/rrr5vVq1ebiooK8+abb9ou2lmjv7/fdHR0mI6ODiPJPPTQQ6ajoyM7PfrBBx800WjUPP3002bPnj3mS1/60ojTxubMmWP+7d/+zbzyyivmk5/8JNPzTvIXf/EXJhqNmueffz5vit6xY8eyx1DXp2/NmjXmhRdeMAcOHDC/+c1vzNe//nXj+7559tlnjTHU8WTKnU1jDHU9Uf7yL//SPP/88+aNN94wv/rVr8xnP/tZU1lZmf2eO5Pq2dkwYowxjzzyiJk3b54pLS011113XXaqJMbmueeeM5KGbbfffrsxJjV1bN26dWbmzJkmEomYj33sY2bPnj155zh+/LhZtWqVmTp1qikvLzef/exnTWdnp4V3c+YaqY4lmccffzx7DHV9+v7sz/4s++/B9OnTzbJly7JBxBjqeDKdHEao64mRWTekpKTEzJ4923zhC18wr732WvbxM6mePWOMmdi2FgAAgLFzcswIAAA4cxBGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWPX/ATyHBtbfYvSOAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-01T17:19:47.601517Z","iopub.execute_input":"2023-07-01T17:19:47.601953Z","iopub.status.idle":"2023-07-01T17:19:47.836583Z","shell.execute_reply.started":"2023-07-01T17:19:47.601920Z","shell.execute_reply":"2023-07-01T17:19:47.835691Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x79f81162e8c0>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}